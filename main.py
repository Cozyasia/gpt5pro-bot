# -*- coding: utf-8 -*-
import os
import re
import json
import base64
import logging
from io import BytesIO

import httpx
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
from telegram.constants import ChatAction

# ========== LOGGING ==========
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
)
log = logging.getLogger("gpt-bot")

# ========== ENV ==========
BOT_TOKEN        = os.environ.get("BOT_TOKEN", "").strip()
PUBLIC_URL       = os.environ.get("PUBLIC_URL", "").strip()   # https://<subdomain>.onrender.com
WEBHOOK_SECRET   = os.environ.get("WEBHOOK_SECRET", "").strip()
BANNER_URL       = os.environ.get("BANNER_URL", "").strip()   # –º–æ–∂–Ω–æ –ø—É—Å—Ç—ã–º
PORT             = int(os.environ.get("PORT", "10000"))

OPENAI_API_KEY   = os.environ.get("OPENAI_API_KEY", "").strip()
OPENAI_MODEL     = os.environ.get("OPENAI_MODEL", "gpt-4o-mini").strip()
TRANSCRIBE_MODEL = os.environ.get("OPENAI_TRANSCRIBE_MODEL", "whisper-1").strip()

DEEPGRAM_API_KEY = os.environ.get("DEEPGRAM_API_KEY", "").strip()
TAVILY_API_KEY   = os.environ.get("TAVILY_API_KEY", "").strip()

if not BOT_TOKEN:
    raise RuntimeError("ENV BOT_TOKEN is required")
if not PUBLIC_URL or not PUBLIC_URL.startswith("http"):
    raise RuntimeError("ENV PUBLIC_URL must look like https://xxx.onrender.com")
if not OPENAI_API_KEY:
    log.warning("OPENAI_API_KEY is empty ‚Äî –æ—Ç–≤–µ—Ç—ã –º–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ –±—É–¥—É—Ç")

# ========== CLIENTS ==========
from openai import OpenAI
oai = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

try:
    if TAVILY_API_KEY:
        from tavily import TavilyClient
        tavily = TavilyClient(api_key=TAVILY_API_KEY)
    else:
        tavily = None
except Exception:
    tavily = None

httpx_client = httpx.AsyncClient(timeout=60)

# ========== PROMPTS ==========
SYSTEM_PROMPT = (
    "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º. "
    "–û—Ç–≤–µ—á–∞–π –ø–æ —Å—É—Ç–∏, –¥–æ–±–∞–≤–ª—è–π —Å–ø–∏—Å–∫–∏ –∏ —à–∞–≥–∏, –∫–æ–≥–¥–∞ —ç—Ç–æ –ø–æ–ª–µ–∑–Ω–æ. "
    "–ï—Å–ª–∏ –ø—Ä–∏–≤–æ–¥–∏—à—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ ‚Äî –≤ –∫–æ–Ω—Ü–µ –¥–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫. "
    "–ù–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã; –µ—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω ‚Äî —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º."
)

VISION_SYSTEM_PROMPT = (
    "–¢—ã –æ–ø–∏—Å—ã–≤–∞–µ—à—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: –ø—Ä–µ–¥–º–µ—Ç—ã, —Ç–µ–∫—Å—Ç, –º–∞–∫–µ—Ç—ã, –≥—Ä–∞—Ñ–∏–∫–∏. "
    "–ù–µ –æ–ø—Ä–µ–¥–µ–ª—è–π –ª–∏—á–Ω–æ—Å—Ç–∏ –ª—é–¥–µ–π –∏ –Ω–µ –¥–∞–≤–∞–π –∏—Ö –∏–º–µ–Ω, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –Ω–∞–ø–µ—á–∞—Ç–∞–Ω—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏. "
    "–ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º."
)

VISION_CAPABILITY_HELP = (
    "–î–∞ ‚Äî —è —É–º–µ—é –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –ø–æ–º–æ–≥–∞—Ç—å —Å –≤–∏–¥–µ–æ.\n\n"
    "‚Ä¢ –§–æ—Ç–æ/—Å–∫—Ä–∏–Ω—à–æ—Ç—ã: –ø—Ä–∏—à–ª–∏ JPG/PNG/WebP ‚Äî –æ–ø–∏—à—É —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏ –∏–∑–≤–ª–µ–∫—É —Ç–µ–∫—Å—Ç.\n"
    "‚Ä¢ –í–∏–¥–µ–æ: –ø—Ä–∏—à–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–π MP4 ‚Äî –∏–∑–≤–ª–µ–∫—É —Ä–µ—á—å –∏ –æ—Ç–≤–µ—á—É –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é; "
    "–¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–±–æ—Ä–∞ –ø—Ä–∏—à–ª–∏ 1‚Äì3 –∫–ª—é—á–µ–≤—ã—Ö –∫–∞–¥—Ä–∞.\n"
    "‚Ä¢ –ì–æ–ª–æ—Å–æ–≤—ã–µ/–∞—É–¥–∏–æ: –æ—Ç–ø—Ä–∞–≤—å –≥–æ–ª–æ—Å–æ–≤–æ–µ ‚Äî —Ä–∞—Å–ø–æ–∑–Ω–∞—é –∏ –æ—Ç–≤–µ—á—É –ø–æ —Å–º—ã—Å–ª—É."
)

# –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –≤–æ–ø—Ä–æ—Å –æ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—è—Ö –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–æ—Ç–æ/–≤–∏–¥–µ–æ/–≥–æ–ª–æ—Å
def asks_about_capabilities(text: str) -> bool:
    t = text.lower()
    has_media_word = any(w in t for w in ("—Ñ–æ—Ç–æ", "–∫–∞—Ä—Ç–∏–Ω–∫", "–∏–∑–æ–±—Ä–∞–∂–µ–Ω", "image", "picture", "–≤–∏–¥–µ–æ", "video", "–≥–æ–ª–æ—Å", "–∞—É–¥–∏–æ"))
    has_action_word = any(w in t for w in ("–∞–Ω–∞–ª–∏–∑", "–∞–Ω–∞–ª–∏–∑–∏—Ä—É", "—Ä–∞—Å–ø–æ–∑–Ω–∞", "–≤–∏–¥–∏—à", "—É–º–µ–µ—à", "–º–æ–∂–µ—à", "–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞", "—Ä–∞–±–æ—Ç–∞–µ—à—å"))
    return has_media_word and has_action_word

_SMALLTALK_RE = re.compile(
    r"^(–ø—Ä–∏–≤–µ—Ç|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π|–¥–æ–±—Ä—ã–π\s*(–¥–µ–Ω—å|–≤–µ—á–µ—Ä|—É—Ç—Ä–æ)|—Ö–∏|hi|hello|—Ö–µ–ª–ª–æ|–∫–∞–∫ –¥–µ–ª–∞|—Å–ø–∞—Å–∏–±–æ|–ø–æ–∫–∞)\b",
    re.IGNORECASE
)
_NEWSY_RE = re.compile(
    r"(–∫–æ–≥–¥–∞|–¥–∞—Ç–∞|–≤—ã–π–¥–µ—Ç|—Ä–µ–ª–∏–∑|–Ω–æ–≤–æ—Å—Ç|–∫—É—Ä—Å|—Ü–µ–Ω–∞|–ø—Ä–æ–≥–Ω–æ–∑|—á—Ç–æ —Ç–∞–∫–æ–µ|–∫—Ç–æ —Ç–∞–∫–æ–π|–Ω–∞–π–¥–∏|—Å—Å—ã–ª–∫–∞|–æ—Ñ–∏—Ü–∏–∞–ª|–∞–¥—Ä–µ—Å|—Ç–µ–ª–µ—Ñ–æ–Ω|"
    r"–ø–æ–≥–æ–¥–∞|—Å–µ–≥–æ–¥–Ω—è|—Å–µ–π—á–∞—Å|—à—Ç—Ä–∞—Ñ|–∑–∞–∫–æ–Ω|—Ç—Ä–µ–Ω–¥|–∫–æ—Ç–∏—Ä–æ–≤–∫|–æ–±–∑–æ—Ä|—Ä–∞—Å–ø–∏—Å–∞–Ω–∏|–∑–∞–ø—É—Å–∫|update|–Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è)",
    re.IGNORECASE
)

def is_smalltalk(text: str) -> bool:
    return bool(_SMALLTALK_RE.search(text.strip()))

def should_browse(text: str) -> bool:
    t = text.strip()
    if is_smalltalk(t):
        return False
    if _NEWSY_RE.search(t) or "?" in t or len(t) > 80:
        return True
    return False

# ========== UTILS ==========
async def typing(ctx: ContextTypes.DEFAULT_TYPE, chat_id: int):
    try:
        await ctx.bot.send_chat_action(chat_id, action=ChatAction.TYPING)
    except Exception:
        pass

def sniff_image_mime(data: bytes) -> str:
    if data.startswith(b"\xff\xd8"):
        return "image/jpeg"
    if data.startswith(b"\x89PNG"):
        return "image/png"
    if data[:4] == b"RIFF" and b"WEBP" in data[:16]:
        return "image/webp"
    return "image/jpeg"

def sniff_av_mime(data: bytes, filename_hint: str = "") -> str:
    name = (filename_hint or "").lower()
    if data[:4] == b"OggS" or name.endswith(".ogg") or "opus" in name:
        return "audio/ogg"
    if data[:3] == b"ID3" or name.endswith(".mp3"):
        return "audio/mpeg"
    if name.endswith(".m4a"):
        return "audio/mp4"
    if b"ftyp" in data[:16] and (name.endswith(".mp4") or name.endswith(".mov") or name.endswith(".m4v")):
        # –¥–ª—è –≤–∏–¥–µ–æ –ø–æ–¥–æ–π–¥—ë—Ç video/mp4 ‚Äî Deepgram —Å–∞–º –≤—ã—Ç–∞—â–∏—Ç –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫—É
        return "video/mp4"
    if name.endswith(".wav"):
        return "audio/wav"
    return "application/octet-stream"

def format_sources(items):
    if not items:
        return ""
    lines = []
    for i, it in enumerate(items, 1):
        title = it.get("title") or it.get("url") or "–ò—Å—Ç–æ—á–Ω–∏–∫"
        url = it.get("url") or ""
        lines.append(f"[{i}] {title} ‚Äî {url}")
    return "\n\n–°—Å—ã–ª–∫–∏:\n" + "\n".join(lines)

def tavily_search(query: str, max_results: int = 5):
    if not tavily:
        return None, []
    try:
        res = tavily.search(
            query=query,
            search_depth="advanced",
            max_results=max_results,
            include_answer=True,
            include_raw_content=False,
        )
        answer = res.get("answer") or ""
        results = res.get("results") or []
        return answer, results
    except Exception as e:
        log.exception("Tavily error: %s", e)
        return None, []

# ========== OPENAI CALLS ==========
async def ask_openai_text(user_text: str, web_ctx: str = "") -> str:
    if not oai:
        return "OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω. –°–æ–æ–±—â–∏ –∞–¥–º–∏–Ω—É."
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    if web_ctx:
        messages.append({"role": "system", "content": f"–í –ø–æ–º–æ—â—å —Ç–µ–±–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –≤–µ–±-–∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏:\n{web_ctx}"})
    messages.append({"role": "user", "content": user_text})
    try:
        resp = oai.chat.completions.create(
            model=OPENAI_MODEL,
            messages=messages,
            temperature=0.6,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        log.exception("OpenAI chat error: %s", e)
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ (–ª–∏–º–∏—Ç/–∫–ª—é—á). –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ."

async def ask_openai_vision(user_text: str, img_b64: str, mime: str) -> str:
    if not oai:
        return "OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω. –°–æ–æ–±—â–∏ –∞–¥–º–∏–Ω—É."
    try:
        resp = oai.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": VISION_SYSTEM_PROMPT},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": user_text or "–û–ø–∏—à–∏, —á—Ç–æ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∏ –∫–∞–∫–æ–π —Ç–∞–º —Ç–µ–∫—Å—Ç."},
                        {"type": "image_url",
                         "image_url": {"url": f"data:{mime};base64,{img_b64}"}}
                    ]
                }
            ],
            temperature=0.4,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        log.exception("Vision error: %s", e)
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –ø—Ä–∏—à–ª–∏ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª."

# ========== STT (Deepgram -> OpenAI fallback) ==========
async def deepgram_transcribe(data: bytes, content_type: str) -> str:
    """–†–∞—Å–ø–æ–∑–Ω–∞—ë–º —Ä–µ—á—å —á–µ—Ä–µ–∑ Deepgram. –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç –∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É."""
    if not DEEPGRAM_API_KEY:
        return ""
    try:
        params = {
            "smart_format": "true",
            "punctuate": "true",
            "language": "ru",   # –º–æ–∂–Ω–æ auto —Å detect_language=true, –Ω–æ —Ç–∞–∫ –±—ã—Å—Ç—Ä–µ–µ/–¥–µ—à–µ–≤–ª–µ
        }
        headers = {
            "Authorization": f"Token {DEEPGRAM_API_KEY}",
            "Content-Type": content_type or "application/octet-stream",
        }
        r = await httpx_client.post(
            "https://api.deepgram.com/v1/listen",
            params=params,
            headers=headers,
            content=data,
        )
        if r.status_code != 200:
            log.error("Deepgram HTTP %s: %s", r.status_code, r.text[:500])
            return ""
        j = r.json()
        # —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
        transcript = (
            j.get("results", {})
             .get("channels", [{}])[0]
             .get("alternatives", [{}])[0]
             .get("transcript", "")
            or j.get("results", {})
             .get("channels", [{}])[0]
             .get("alternatives", [{}])[0]
             .get("paragraphs", {})
             .get("transcript", "")
        )
        return (transcript or "").strip()
    except Exception as e:
        log.exception("Deepgram error: %s", e)
        return ""

async def openai_transcribe(buf: BytesIO, filename_hint: str) -> str:
    if not oai:
        return ""
    try:
        buf.seek(0)
        setattr(buf, "name", filename_hint)
        tr = oai.audio.transcriptions.create(model=TRANSCRIBE_MODEL, file=buf)
        return (tr.text or "").strip()
    except Exception as e:
        log.exception("OpenAI Whisper error: %s", e)
        return ""

async def transcribe_audio_unified(raw: bytes, filename_hint: str = "") -> str:
    """–ï–¥–∏–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞: —Å–Ω–∞—á–∞–ª–∞ Deepgram, –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî OpenAI Whisper."""
    ct = sniff_av_mime(raw, filename_hint)
    # 1) Deepgram
    if DEEPGRAM_API_KEY:
        text = await deepgram_transcribe(raw, ct)
        if text:
            return text
    # 2) OpenAI fallback (–Ω—É–∂–Ω–æ file-like)
    buf = BytesIO(raw)
    return await openai_transcribe(buf, filename_hint or "audio.bin")

# ========== HANDLERS ==========
START_GREETING = (
    "–ü—Ä–∏–≤–µ—Ç! –Ø –≥–æ—Ç–æ–≤. –ù–∞–ø–∏—à–∏ –ª—é–±–æ–π –≤–æ–ø—Ä–æ—Å.\n\n"
    "–ü–æ–¥—Å–∫–∞–∑–∫–∏:\n"
    "‚Ä¢ –Ø –∏—â—É —Å–≤–µ–∂—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –¥–ª—è —Ñ–∞–∫—Ç–æ–≤ –∏ –¥–∞—Ç, –∫–æ–≥–¥–∞ —ç—Ç–æ –Ω—É–∂–Ω–æ.\n"
    "‚Ä¢ –ü—Ä–∏–º–µ—Ä—ã: ¬´–ö–æ–≥–¥–∞ –≤—ã–π–¥–µ—Ç GTA 6?¬ª, ¬´–ö—É—Ä—Å –±–∏—Ç–∫–æ–∏–Ω–∞ —Å–µ–π—á–∞—Å –∏ –ø—Ä–æ–≥–Ω–æ–∑¬ª, "
    "¬´–ù–∞–π–¥–∏ —É—á–µ–±–Ω–∏–∫ –∞–ª–≥–µ–±—Ä—ã 11 –∫–ª–∞—Å—Å (–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏)¬ª, ¬´–ù–æ–≤–æ—Å—Ç–∏ –ø–æ ‚Ä¶?¬ª\n"
    "‚Ä¢ –ú–æ–∂–Ω–æ –ø—Ä–∏—Å–ª–∞—Ç—å —Ñ–æ—Ç–æ ‚Äî –æ–ø–∏—à—É –∏ –∏–∑–≤–ª–µ–∫—É —Ç–µ–∫—Å—Ç.\n"
    "‚Ä¢ –ú–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ/–∞—É–¥–∏–æ/–≤–∏–¥–µ–æ ‚Äî —Ä–∞—Å–ø–æ–∑–Ω–∞—é —Ä–µ—á—å –∏ –æ—Ç–≤–µ—á—É –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é."
)

async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if BANNER_URL:
        try:
            await update.effective_message.reply_photo(BANNER_URL)
        except Exception:
            pass
    await update.effective_message.reply_text(START_GREETING)

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (update.message.text or "").strip()
    chat_id = update.effective_chat.id

    # –Ø–≤–Ω—ã–π –≤–æ–ø—Ä–æ—Å –ø—Ä–æ ¬´—É–º–µ–µ—à—å –ª–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å‚Ä¶¬ª ‚Äî –æ—Ç–≤–µ—á–∞–µ–º —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º
    if asks_about_capabilities(text):
        await update.message.reply_text(VISION_CAPABILITY_HELP, disable_web_page_preview=True)
        return

    await typing(context, chat_id)

    if is_smalltalk(text):
        reply = await ask_openai_text(text)
        await update.message.reply_text(reply)
        return

    web_ctx = ""
    sources = []
    if should_browse(text):
        answer_from_search, results = tavily_search(text, max_results=5)
        sources = results or []
        ctx_lines = []
        if answer_from_search:
            ctx_lines.append(f"–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ–∏—Å–∫–æ–º: {answer_from_search}")
        for i, it in enumerate(sources, 1):
            ctx_lines.append(f"[{i}] {it.get('title','')}: {it.get('url','')}")
        web_ctx = "\n".join(ctx_lines)

    answer = await ask_openai_text(text, web_ctx=web_ctx)
    answer += format_sources(sources)
    await update.message.reply_text(answer, disable_web_page_preview=False)

async def on_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await typing(context, chat_id)

    photo = update.message.photo[-1]
    file = await context.bot.get_file(photo.file_id)
    buf = BytesIO()
    await file.download_to_memory(buf)
    data = buf.getvalue()

    mime = sniff_image_mime(data)
    img_b64 = base64.b64encode(data).decode("ascii")
    user_text = (update.message.caption or "").strip()

    answer = await ask_openai_vision(user_text, img_b64, mime)
    await update.message.reply_text(answer, disable_web_page_preview=True)

async def handle_stt_reply(update: Update, recognized_text: str):
    """–û–±—â–∏–π –æ—Ç–≤–µ—Ç –ø–æ—Å–ª–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏."""
    prefix = f"üó£Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–ª: ¬´{recognized_text}¬ª\n\n"
    web_ctx = ""
    sources = []
    if should_browse(recognized_text):
        answer_from_search, results = tavily_search(recognized_text, max_results=5)
        sources = results or []
        ctx_lines = []
        if answer_from_search:
            ctx_lines.append(f"–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ–∏—Å–∫–æ–º: {answer_from_search}")
        for i, it in enumerate(sources, 1):
            ctx_lines.append(f"[{i}] {it.get('title','')}: {it.get('url','')}")
        web_ctx = "\n".join(ctx_lines)

    answer = await ask_openai_text(recognized_text, web_ctx=web_ctx)
    return prefix + answer + format_sources(sources)

async def on_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Telegram voice (OGG/OPUS)."""
    chat_id = update.effective_chat.id
    await typing(context, chat_id)

    file = await context.bot.get_file(update.message.voice.file_id)
    buf = BytesIO()
    await file.download_to_memory(buf)
    raw = buf.getvalue()

    text = await transcribe_audio_unified(raw, filename_hint="audio.ogg")
    if not text:
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.")
        return

    reply = await handle_stt_reply(update, text)
    await update.message.reply_text(reply, disable_web_page_preview=False)

async def on_audio(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—ã—á–Ω—ã–µ –∞—É–¥–∏–æ-—Ñ–∞–π–ª—ã (mp3/m4a/wav)."""
    chat_id = update.effective_chat.id
    await typing(context, chat_id)

    audio = update.message.audio
    file = await context.bot.get_file(audio.file_id)
    buf = BytesIO()
    await file.download_to_memory(buf)
    raw = buf.getvalue()

    filename = (audio.file_name or "audio.mp3")
    text = await transcribe_audio_unified(raw, filename_hint=filename)
    if not text:
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∞—É–¥–∏–æ. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.")
        return

    reply = await handle_stt_reply(update, text)
    await update.message.reply_text(reply, disable_web_page_preview=False)

async def on_video(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ—Ä–æ—Ç–∫–∏–µ –≤–∏–¥–µ–æ (mp4) ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ü–µ–ª–∏–∫–æ–º –≤ Deepgram, –æ–Ω —Å–∞–º –≤—ã—Ç–∞—â–∏—Ç –∞—É–¥–∏–æ."""
    chat_id = update.effective_chat.id
    await typing(context, chat_id)

    video = update.message.video
    file = await context.bot.get_file(video.file_id)
    buf = BytesIO()
    await file.download_to_memory(buf)
    raw = buf.getvalue()

    filename = (video.file_name or "video.mp4")
    text = await transcribe_audio_unified(raw, filename_hint=filename)
    if not text:
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ä–µ—á—å –∏–∑ –≤–∏–¥–µ–æ. –ü—Ä–∏—à–ª–∏ 1‚Äì3 –∫–∞–¥—Ä–∞ (—Å–∫—Ä–∏–Ω—à–æ—Ç–∞) ‚Äî —Ä–∞–∑–±–µ—Ä—É –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º.")
        return

    reply = await handle_stt_reply(update, text)
    await update.message.reply_text(reply, disable_web_page_preview=False)

# ========== BOOTSTRAP ==========
def build_app():
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))
    app.add_handler(MessageHandler(filters.PHOTO, on_photo))
    app.add_handler(MessageHandler(filters.VOICE, on_voice))
    app.add_handler(MessageHandler(filters.AUDIO, on_audio))
    app.add_handler(MessageHandler(filters.VIDEO, on_video))
    return app

def run_webhook(app):
    url_path = f"webhook/{BOT_TOKEN}"
    webhook_url = f"{PUBLIC_URL.rstrip('/')}/{url_path}"

    log.info("Starting webhook on 0.0.0.0:%s  ->  %s", PORT, webhook_url)
    # –í–ê–ñ–ù–û: —Ç–æ–ª—å–∫–æ webhook, –±–µ–∑ polling ‚Äî –∏–Ω–∞—á–µ –±—É–¥–µ—Ç 409 Conflict
    app.run_webhook(
        listen="0.0.0.0",
        port=PORT,
        url_path=url_path,
        webhook_url=webhook_url,
        secret_token=WEBHOOK_SECRET or None,
        drop_pending_updates=True,
    )

def main():
    app = build_app()
    run_webhook(app)

if __name__ == "__main__":
    main()

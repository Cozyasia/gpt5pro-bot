# -*- coding: utf-8 -*-
import os
import re
import json
import base64
import logging
from io import BytesIO

from telegram import Update
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
)
from telegram.constants import ChatAction

# ========== LOGGING ==========
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
)
log = logging.getLogger("gpt-bot")

# ========== ENV ==========
BOT_TOKEN       = os.environ.get("BOT_TOKEN", "").strip()
PUBLIC_URL      = os.environ.get("PUBLIC_URL", "").strip()   # https://<subdomain>.onrender.com
OPENAI_API_KEY  = os.environ.get("OPENAI_API_KEY", "").strip()
OPENAI_MODEL    = os.environ.get("OPENAI_MODEL", "gpt-4o-mini").strip()
WEBHOOK_SECRET  = os.environ.get("WEBHOOK_SECRET", "").strip()
BANNER_URL      = os.environ.get("BANNER_URL", "").strip()   # –º–æ–∂–Ω–æ –ø—É—Å—Ç—ã–º
TAVILY_API_KEY  = os.environ.get("TAVILY_API_KEY", "").strip()
TRANSCRIBE_MODEL = os.environ.get("OPENAI_TRANSCRIBE_MODEL", "whisper-1").strip()
PORT            = int(os.environ.get("PORT", "10000"))

if not BOT_TOKEN:
    raise RuntimeError("ENV BOT_TOKEN is required")
if not PUBLIC_URL or not PUBLIC_URL.startswith("http"):
    raise RuntimeError("ENV PUBLIC_URL must look like https://xxx.onrender.com")
if not OPENAI_API_KEY:
    log.warning("OPENAI_API_KEY is empty ‚Äî –æ—Ç–≤–µ—Ç—ã –º–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ –±—É–¥—É—Ç")

# ========== OPENAI / Tavily clients ==========
from openai import OpenAI
oai = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

try:
    if TAVILY_API_KEY:
        from tavily import TavilyClient
        tavily = TavilyClient(api_key=TAVILY_API_KEY)
    else:
        tavily = None
except Exception:
    tavily = None

# ========== PROMPTS & HEURISTICS ==========
SYSTEM_PROMPT = (
    "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º. "
    "–û—Ç–≤–µ—á–∞–π –ø–æ —Å—É—Ç–∏, –¥–æ–±–∞–≤–ª—è–π —Å–ø–∏—Å–∫–∏ –∏ —à–∞–≥–∏, –∫–æ–≥–¥–∞ —ç—Ç–æ –ø–æ–ª–µ–∑–Ω–æ. "
    "–ï—Å–ª–∏ –ø—Ä–∏–≤–æ–¥–∏—à—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ ‚Äî –≤ –∫–æ–Ω—Ü–µ –¥–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫. "
    "–ù–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã; –µ—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω ‚Äî —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º."
)

VISION_SYSTEM_PROMPT = (
    "–¢—ã –æ–ø–∏—Å—ã–≤–∞–µ—à—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: –ø—Ä–µ–¥–º–µ—Ç—ã, —Ç–µ–∫—Å—Ç, –º–∞–∫–µ—Ç—ã, –≥—Ä–∞—Ñ–∏–∫–∏. "
    "–ù–µ –æ–ø—Ä–µ–¥–µ–ª—è–π –ª–∏—á–Ω–æ—Å—Ç–∏ –ª—é–¥–µ–π –∏ –Ω–µ –¥–∞–≤–∞–π –∏—Ö –∏–º–µ–Ω, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –Ω–∞–ø–µ—á–∞—Ç–∞–Ω—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏. "
    "–ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º."
)

VISION_CAPABILITY_HELP = (
    "–î–∞ ‚Äî —è —É–º–µ—é –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü—Ä–∏–∫—Ä–µ–ø–∏ —Ñ–æ—Ç–æ –∏–ª–∏ —Å–∫—Ä–∏–Ω—à–æ—Ç üìé\n"
    "‚Ä¢ –§–æ—Ä–º–∞—Ç—ã: JPG/PNG/WebP, –¥–æ ~10 –ú–ë.\n"
    "‚Ä¢ PDF –∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã ‚Äî –ø—Ä–∏—à–ª–∏ –∫–∞–∫ *—Ñ–∞–π–ª*, –∏–∑–≤–ª–µ–∫—É —Ç–µ–∫—Å—Ç/—Ç–∞–±–ª–∏—Ü—ã.\n"
    "‚Ä¢ –í–∏–¥–µ–æ: –ø—Ä–∏—à–ª–∏ 1‚Äì3 —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ (–∫–∞–¥—Ä–∞) ‚Äî –æ–ø–∏—à—É –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø–æ –∫–∞–¥—Ä–∞–º.\n"
    "–ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω ‚Äî –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤—å –≤–æ–ø—Ä–æ—Å –∫ –Ω–µ–º—É üòâ"
)

_SMALLTALK_RE = re.compile(
    r"^(–ø—Ä–∏–≤–µ—Ç|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π|–¥–æ–±—Ä—ã–π\s*(–¥–µ–Ω—å|–≤–µ—á–µ—Ä|—É—Ç—Ä–æ)|—Ö–∏|hi|hello|—Ö–µ–ª–ª–æ|–∫–∞–∫ –¥–µ–ª–∞|—Å–ø–∞—Å–∏–±–æ|–ø–æ–∫–∞)\b",
    re.IGNORECASE
)
_NEWSY_RE = re.compile(
    r"(–∫–æ–≥–¥–∞|–¥–∞—Ç–∞|–≤—ã–π–¥–µ—Ç|—Ä–µ–ª–∏–∑|–Ω–æ–≤–æ—Å—Ç|–∫—É—Ä—Å|—Ü–µ–Ω–∞|–ø—Ä–æ–≥–Ω–æ–∑|—á—Ç–æ —Ç–∞–∫–æ–µ|–∫—Ç–æ —Ç–∞–∫–æ–π|–Ω–∞–π–¥–∏|—Å—Å—ã–ª–∫–∞|–æ—Ñ–∏—Ü–∏–∞–ª|–∞–¥—Ä–µ—Å|—Ç–µ–ª–µ—Ñ–æ–Ω|"
    r"–ø–æ–≥–æ–¥–∞|—Å–µ–≥–æ–¥–Ω—è|—Å–µ–π—á–∞—Å|—à—Ç—Ä–∞—Ñ|–∑–∞–∫–æ–Ω|—Ç—Ä–µ–Ω–¥|–∫–æ—Ç–∏—Ä–æ–≤–∫|–æ–±–∑–æ—Ä|—Ä–∞—Å–ø–∏—Å–∞–Ω–∏|–∑–∞–ø—É—Å–∫|update|–Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è)",
    re.IGNORECASE
)
_CAPABILITY_RE = re.compile(
    r"(–º–æ–∂(–µ—à—å|–Ω–æ)\s*(–ª–∏\s*)?(–∞–Ω–∞–ª–∏–∑(–∏—Ä–æ–≤–∞—Ç—å)?|—Ä–∞—Å–ø–æ–∑–Ω–∞–≤(–∞—Ç—å|–∞–Ω–∏–µ))\s*(—Ñ–æ—Ç–æ|–∫–∞—Ä—Ç–∏–Ω–∫|–∏–∑–æ–±—Ä–∞–∂–µ–Ω|image|picture)|"
    r"–∞–Ω–∞–ª–∏–∑(–∏—Ä–æ–≤–∞—Ç—å)?\s*(—Ñ–æ—Ç–æ|–∫–∞—Ä—Ç–∏–Ω–∫|–∏–∑–æ–±—Ä–∞–∂–µ–Ω)|"
    r"(–º–æ–∂(–µ—à—å|–Ω–æ)\s*(–ª–∏\s*)?)?(–∞–Ω–∞–ª–∏–∑|—Ä–∞–±–æ—Ç–∞—Ç—å)\s*—Å\s*–≤–∏–¥–µ–æ)",
    re.IGNORECASE
)

def is_smalltalk(text: str) -> bool:
    return bool(_SMALLTALK_RE.search(text.strip()))

def should_browse(text: str) -> bool:
    t = text.strip()
    if is_smalltalk(t):
        return False
    # –µ—Å–ª–∏ —è–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è —Ü–µ–ª—å –∏–ª–∏ –≤–æ–ø—Ä–æ—Å ‚Äì —Å–º–æ—Ç—Ä–∏–º –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç
    if _NEWSY_RE.search(t) or "?" in t or len(t) > 80:
        return True
    return False

def is_vision_capability_question(text: str) -> bool:
    return bool(_CAPABILITY_RE.search(text))

# ========== UTILS ==========
async def typing(ctx: ContextTypes.DEFAULT_TYPE, chat_id: int):
    try:
        await ctx.bot.send_chat_action(chat_id, action=ChatAction.TYPING)
    except Exception:
        pass

def sniff_image_mime(data: bytes) -> str:
    if data.startswith(b"\xff\xd8"):
        return "image/jpeg"
    if data.startswith(b"\x89PNG"):
        return "image/png"
    if data[:4] == b"RIFF" and b"WEBP" in data[:16]:
        return "image/webp"
    return "image/jpeg"

def format_sources(items):
    if not items:
        return ""
    lines = []
    for i, it in enumerate(items, 1):
        title = it.get("title") or it.get("url") or "–ò—Å—Ç–æ—á–Ω–∏–∫"
        url = it.get("url") or ""
        lines.append(f"[{i}] {title} ‚Äî {url}")
    return "\n\n–°—Å—ã–ª–∫–∏:\n" + "\n".join(lines)

def tavily_search(query: str, max_results: int = 5):
    if not tavily:
        return None, []
    try:
        res = tavily.search(
            query=query,
            search_depth="advanced",
            max_results=max_results,
            include_answer=True,
            include_raw_content=False,
        )
        answer = res.get("answer") or ""
        results = res.get("results") or []
        return answer, results
    except Exception as e:
        log.exception("Tavily error: %s", e)
        return None, []

async def ask_openai_text(user_text: str, web_ctx: str = "") -> str:
    """–ß–∏—Å—Ç–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç (—Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —Å—Å—ã–ª–æ–∫)."""
    if not oai:
        return "OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω. –°–æ–æ–±—â–∏ –∞–¥–º–∏–Ω—É."
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    if web_ctx:
        messages.append({"role": "system", "content": f"–í –ø–æ–º–æ—â—å —Ç–µ–±–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –≤–µ–±-–∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏:\n{web_ctx}"})
    messages.append({"role": "user", "content": user_text})
    try:
        resp = oai.chat.completions.create(
            model=OPENAI_MODEL,
            messages=messages,
            temperature=0.6,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        log.exception("OpenAI chat error: %s", e)
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ –ø–æ–∑–∂–µ."

async def ask_openai_vision(user_text: str, img_b64: str, mime: str) -> str:
    """–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è + —Ç–µ–∫—Å—Ç–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å."""
    if not oai:
        return "OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω. –°–æ–æ–±—â–∏ –∞–¥–º–∏–Ω—É."
    try:
        resp = oai.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": VISION_SYSTEM_PROMPT},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": user_text or "–û–ø–∏—à–∏, —á—Ç–æ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∏ –∫–∞–∫–æ–π —Ç–∞–º —Ç–µ–∫—Å—Ç."},
                        {"type": "image_url",
                         "image_url": {"url": f"data:{mime};base64,{img_b64}"}}
                    ]
                }
            ],
            temperature=0.4,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        log.exception("Vision error: %s", e)
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –ø—Ä–∏—à–ª–∏ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª."

async def transcribe_audio(buf: BytesIO, filename_hint: str = "audio.ogg") -> str:
    """–†–∞—Å–ø–æ–∑–Ω–∞—ë–º –≥–æ–ª–æ—Å (OGG/OPUS –∏ –ø—Ä.), –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç."""
    if not oai:
        return ""
    try:
        # OpenAI SDK –æ–∂–∏–¥–∞–µ—Ç file-like —Å –∏–º–µ–Ω–µ–º; –ø—Ä–∏—Å–≤–æ–∏–º BytesIO ¬´name¬ª
        buf.seek(0)
        setattr(buf, "name", filename_hint)
        tr = oai.audio.transcriptions.create(
            model=TRANSCRIBE_MODEL,
            file=buf
        )
        text = (tr.text or "").strip()
        return text
    except Exception as e:
        log.exception("Transcribe error: %s", e)
        return ""

# ========== HANDLERS ==========
START_GREETING = (
    "–ü—Ä–∏–≤–µ—Ç! –Ø –≥–æ—Ç–æ–≤. –ù–∞–ø–∏—à–∏ –ª—é–±–æ–π –≤–æ–ø—Ä–æ—Å.\n\n"
    "–ü–æ–¥—Å–∫–∞–∑–∫–∏:\n"
    "‚Ä¢ –Ø –∏—â—É —Å–≤–µ–∂—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –¥–ª—è —Ñ–∞–∫—Ç–æ–≤ –∏ –¥–∞—Ç, –∫–æ–≥–¥–∞ —ç—Ç–æ –Ω—É–∂–Ω–æ.\n"
    "‚Ä¢ –ü—Ä–∏–º–µ—Ä—ã: ¬´–ö–æ–≥–¥–∞ –≤—ã–π–¥–µ—Ç GTA 6?¬ª, ¬´–ö—É—Ä—Å –±–∏—Ç–∫–æ–∏–Ω–∞ —Å–µ–π—á–∞—Å –∏ –ø—Ä–æ–≥–Ω–æ–∑¬ª, "
    "¬´–ù–∞–π–¥–∏ —É—á–µ–±–Ω–∏–∫ –∞–ª–≥–µ–±—Ä—ã 11 –∫–ª–∞—Å—Å (–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏)¬ª, ¬´–ù–æ–≤–æ—Å—Ç–∏ –ø–æ ...?¬ª\n"
    "‚Ä¢ –ú–æ–∂–Ω–æ –ø—Ä–∏—Å–ª–∞—Ç—å —Ñ–æ—Ç–æ ‚Äî –æ–ø–∏—à—É –∏ –∏–∑–≤–ª–µ–∫—É —Ç–µ–∫—Å—Ç.\n"
    "‚Ä¢ –ú–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ ‚Äî —è —Ä–∞—Å–ø–æ–∑–Ω–∞—é –∏ –æ—Ç–≤–µ—á—É –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é."
)

async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # –±–∞–Ω–Ω–µ—Ä ‚Äî –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
    if BANNER_URL:
        try:
            await update.effective_message.reply_photo(BANNER_URL)
        except Exception:
            pass
    await update.effective_message.reply_text(START_GREETING)

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (update.message.text or "").strip()
    chat_id = update.effective_chat.id

    # –í–æ–ø—Ä–æ—Å –ø—Ä–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π/–≤–∏–¥–µ–æ
    if is_vision_capability_question(text):
        await update.message.reply_text(VISION_CAPABILITY_HELP, disable_web_page_preview=True)
        return

    await typing(context, chat_id)

    # –ú–∞–ª–µ–Ω—å–∫–∏–µ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è ‚Äî –±–µ–∑ –≤–µ–±–∞
    if is_smalltalk(text):
        reply = await ask_openai_text(text)
        await update.message.reply_text(reply)
        return

    # –ù—É–∂–µ–Ω –ª–∏ –≤–µ–±-–ø–æ–∏—Å–∫?
    web_ctx = ""
    sources = []
    if should_browse(text):
        answer_from_search, results = tavily_search(text, max_results=5)
        sources = results or []
        # –ö—Ä–∞—Ç–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –º–æ–¥–µ–ª–∏ (–æ—Ç–≤–µ—Ç + —Å—Å—ã–ª–∫–∏)
        ctx_lines = []
        if answer_from_search:
            ctx_lines.append(f"–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ–∏—Å–∫–æ–º: {answer_from_search}")
        for i, it in enumerate(sources, 1):
            ctx_lines.append(f"[{i}] {it.get('title','')}: {it.get('url','')}")
        web_ctx = "\n".join(ctx_lines)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏
    answer = await ask_openai_text(text, web_ctx=web_ctx)

    # –ü—Ä–∏–∫–ª–µ–∏–º —è–≤–Ω—ã–µ —Å—Å—ã–ª–∫–∏ (–µ—Å–ª–∏ –±—ã–ª–∏)
    answer += format_sources(sources)
    await update.message.reply_text(answer, disable_web_page_preview=False)

async def on_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await typing(context, chat_id)

    # –±–µ—Ä—ë–º —Å–∞–º—ã–π –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä
    photo = update.message.photo[-1]
    file = await context.bot.get_file(photo.file_id)
    buf = BytesIO()
    await file.download_to_memory(buf)
    data = buf.getvalue()

    mime = sniff_image_mime(data)
    img_b64 = base64.b64encode(data).decode("ascii")

    # –ø–æ–ø—Ä–æ–±—É–µ–º –≤–∑—è—Ç—å –ø–æ–¥–ø–∏—Å—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∫–∞–∫ –≤–æ–ø—Ä–æ—Å
    user_text = (update.message.caption or "").strip()

    answer = await ask_openai_vision(user_text, img_b64, mime)
    await update.message.reply_text(answer, disable_web_page_preview=True)

async def on_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Voice message (OGG/OPUS)."""
    chat_id = update.effective_chat.id
    await typing(context, chat_id)

    voice = update.message.voice
    file = await context.bot.get_file(voice.file_id)
    buf = BytesIO()
    await file.download_to_memory(buf)

    text = await transcribe_audio(buf, filename_hint="audio.ogg")
    if not text:
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.")
        return

    # –û—Ç–≤–µ—á–∞–µ–º –ø–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É (–∏ –º—è–≥–∫–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ –±—ã–ª–æ –ø–æ–Ω—è—Ç–æ)
    prefix = f"üó£Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–ª: ¬´{text}¬ª\n\n"
    web_ctx = ""
    sources = []
    if should_browse(text):
        answer_from_search, results = tavily_search(text, max_results=5)
        sources = results or []
        ctx_lines = []
        if answer_from_search:
            ctx_lines.append(f"–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ–∏—Å–∫–æ–º: {answer_from_search}")
        for i, it in enumerate(sources, 1):
            ctx_lines.append(f"[{i}] {it.get('title','')}: {it.get('url','')}")
        web_ctx = "\n".join(ctx_lines)

    answer = await ask_openai_text(text, web_ctx=web_ctx)
    answer = prefix + answer + format_sources(sources)
    await update.message.reply_text(answer, disable_web_page_preview=False)

async def on_audio(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—ã—á–Ω—ã–µ –∞—É–¥–∏–æ-—Ñ–∞–π–ª—ã (mp3/m4a/wav) ‚Äî –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ voice."""
    chat_id = update.effective_chat.id
    await typing(context, chat_id)

    audio = update.message.audio
    file = await context.bot.get_file(audio.file_id)
    buf = BytesIO()
    await file.download_to_memory(buf)

    # –ü–æ–ø—Ä–æ–±—É–µ–º —É–≥–∞–¥–∞—Ç—å –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ –ø–æ–¥–ø–∏—Å–∏/–º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    filename = (audio.file_name or "audio.mp3")
    text = await transcribe_audio(buf, filename_hint=filename)
    if not text:
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∞—É–¥–∏–æ. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.")
        return

    prefix = f"üó£Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–ª: ¬´{text}¬ª\n\n"
    web_ctx = ""
    sources = []
    if should_browse(text):
        answer_from_search, results = tavily_search(text, max_results=5)
        sources = results or []
        ctx_lines = []
        if answer_from_search:
            ctx_lines.append(f"–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ–∏—Å–∫–æ–º: {answer_from_search}")
        for i, it in enumerate(sources, 1):
            ctx_lines.append(f"[{i}] {it.get('title','')}: {it.get('url','')}")
        web_ctx = "\n".join(ctx_lines)

    answer = await ask_openai_text(text, web_ctx=web_ctx)
    answer = prefix + answer + format_sources(sources)
    await update.message.reply_text(answer, disable_web_page_preview=False)

# ========== BOOTSTRAP ==========
def build_app():
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", cmd_start))
    # —Ç–µ–∫—Å—Ç
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))
    # —Ñ–æ—Ç–æ
    app.add_handler(MessageHandler(filters.PHOTO, on_photo))
    # –≥–æ–ª–æ—Å–æ–≤—ã–µ (voice) –∏ –∞—É–¥–∏–æ
    app.add_handler(MessageHandler(filters.VOICE, on_voice))
    app.add_handler(MessageHandler(filters.AUDIO, on_audio))
    return app

def run_webhook(app):
    # —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å (—á—Ç–æ–± –Ω–∏–∫—Ç–æ —Å–ª—É—á–∞–π–Ω–æ –Ω–µ –¥–µ—Ä–≥–∞–ª)
    url_path = f"webhook/{BOT_TOKEN}"
    webhook_url = f"{PUBLIC_URL.rstrip('/')}/{url_path}"

    log.info("Starting webhook on 0.0.0.0:%s  ->  %s", PORT, webhook_url)
    app.run_webhook(
        listen="0.0.0.0",
        port=PORT,
        url_path=url_path,
        webhook_url=webhook_url,
        secret_token=WEBHOOK_SECRET or None,   # Telegram header X-Telegram-Bot-Api-Secret-Token
        drop_pending_updates=True,
    )

def main():
    app = build_app()
    run_webhook(app)

if __name__ == "__main__":
    main()

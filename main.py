# -*- coding: utf-8 -*-
import os
import re
import json
import time
import base64
import logging
from io import BytesIO
import asyncio

import httpx
from telegram import Update, ReplyKeyboardMarkup, KeyboardButton, WebAppInfo, InputFile
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
)
from telegram.constants import ChatAction

# -------- LOGGING --------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
)
log = logging.getLogger("gpt-bot")

# -------- ENV --------
BOT_TOKEN        = os.environ.get("BOT_TOKEN", "").strip()
PUBLIC_URL       = os.environ.get("PUBLIC_URL", "").strip()
WEBAPP_URL       = os.environ.get("WEBAPP_URL", "").strip()
OPENAI_API_KEY   = os.environ.get("OPENAI_API_KEY", "").strip()      # LLM (OpenRouter –∏–ª–∏ OpenAI)
OPENAI_BASE_URL  = os.environ.get("OPENAI_BASE_URL", "").strip()     # –Ω–∞–ø—Ä. https://openrouter.ai/api/v1
OPENAI_MODEL     = os.environ.get("OPENAI_MODEL", "openai/gpt-4o-mini").strip()

OPENROUTER_SITE_URL = os.environ.get("OPENROUTER_SITE_URL", "").strip()
OPENROUTER_APP_NAME = os.environ.get("OPENROUTER_APP_NAME", "").strip()

WEBHOOK_SECRET   = os.environ.get("WEBHOOK_SECRET", "").strip()
BANNER_URL       = os.environ.get("BANNER_URL", "").strip()
TAVILY_API_KEY   = os.environ.get("TAVILY_API_KEY", "").strip()

# STT:
DEEPGRAM_API_KEY = os.environ.get("DEEPGRAM_API_KEY", "").strip()
OPENAI_STT_KEY   = os.environ.get("OPENAI_STT_KEY", "").strip()      # –æ—Ç–¥–µ–ª—å–Ω—ã–π OpenAI –∫–ª—é—á –¥–ª—è Whisper (–æ–ø—Ü.)
TRANSCRIBE_MODEL = os.environ.get("OPENAI_TRANSCRIBE_MODEL", "whisper-1").strip()

# Media:
RUNWAY_API_KEY   = os.environ.get("RUNWAY_API_KEY", "").strip()      # –∫–ª—é—á Runway (dev.runwayml.com ‚Üí API Keys)
OPENAI_IMAGE_KEY = os.environ.get("OPENAI_IMAGE_KEY", "").strip() or OPENAI_API_KEY  # –æ–±—ã—á–Ω—ã–π OpenAI –∫–ª—é—á (–¥–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫)

# NEW: Premium –¥–æ—Å—Ç—É–ø –∫ Runway (—Å–ø–∏—Å–æ–∫ TG user_id —á–µ—Ä–µ–∑ ENV, —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã—Ö –∑–∞–ø—è—Ç—ã–º–∏)
PREMIUM_USER_IDS = set(
    int(x) for x in os.environ.get("PREMIUM_USER_IDS", "").split(",") if x.strip().isdigit()
)

PORT             = int(os.environ.get("PORT", "10000"))

if not BOT_TOKEN:
    raise RuntimeError("ENV BOT_TOKEN is required")
if not PUBLIC_URL or not PUBLIC_URL.startswith("http"):
    raise RuntimeError("ENV PUBLIC_URL must look like https://xxx.onrender.com")
if not OPENAI_API_KEY:
    raise RuntimeError("ENV OPENAI_API_KEY is required")

WEB_ROOT = WEBAPP_URL or PUBLIC_URL

# -------- OPENAI / Tavily clients --------
from openai import OpenAI

# LLM (OpenRouter –∏–ª–∏ OpenAI)
default_headers = {}
if OPENROUTER_SITE_URL:
    default_headers["HTTP-Referer"] = OPENROUTER_SITE_URL
if OPENROUTER_APP_NAME:
    default_headers["X-Title"] = OPENROUTER_APP_NAME

oai_llm = OpenAI(
    api_key=OPENAI_API_KEY,
    base_url=OPENAI_BASE_URL or None,
    default_headers=default_headers or None,
)

# Whisper (–µ—Å–ª–∏ –µ—Å—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π –∫–ª—é—á OpenAI)
oai_stt = None
if OPENAI_STT_KEY:
    oai_stt = OpenAI(api_key=OPENAI_STT_KEY)  # –≤—Å–µ–≥–¥–∞ api.openai.com

# Images API ‚Äî –≤—Å–µ–≥–¥–∞ api.openai.com
oai_img = OpenAI(api_key=OPENAI_IMAGE_KEY)

# Tavily
try:
    if TAVILY_API_KEY:
        from tavily import TavilyClient
        tavily = TavilyClient(api_key=TAVILY_API_KEY)
    else:
        tavily = None
except Exception:
    tavily = None

# -------- PROMPTS --------
SYSTEM_PROMPT = (
    "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º. "
    "–û—Ç–≤–µ—á–∞–π –ø–æ —Å—É—Ç–∏, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π —Å–ø–∏—Å–∫–∞–º–∏/—à–∞–≥–∞–º–∏, –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã. "
    "–ï—Å–ª–∏ —Å—Å—ã–ª–∞–µ—à—å—Å—è –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ ‚Äî –≤ –∫–æ–Ω—Ü–µ –¥–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫."
)
VISION_SYSTEM_PROMPT = (
    "–¢—ã —á—ë—Ç–∫–æ –æ–ø–∏—Å—ã–≤–∞–µ—à—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: –æ–±—ä–µ–∫—Ç—ã, —Ç–µ–∫—Å—Ç, —Å—Ö–µ–º—ã, –≥—Ä–∞—Ñ–∏–∫–∏. "
    "–ù–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–π –ª–∏—á–Ω–æ—Å—Ç–∏ –ª—é–¥–µ–π –∏ –Ω–µ –ø–∏—à–∏ –∏–º–µ–Ω–∞, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –Ω–∞–ø–µ—á–∞—Ç–∞–Ω—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."
)

# -------- HEURISTICS --------
_SMALLTALK_RE = re.compile(
    r"^(–ø—Ä–∏–≤–µ—Ç|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π|–¥–æ–±—Ä—ã–π\s*(–¥–µ–Ω—å|–≤–µ—á–µ—Ä|—É—Ç—Ä–æ)|—Ö–∏|hi|hello|—Ö–µ–ª–ª–æ|–∫–∞–∫ –¥–µ–ª–∞|—Å–ø–∞—Å–∏–±–æ|–ø–æ–∫–∞)\b",
    re.IGNORECASE
)
_NEWSY_RE = re.compile(
    r"(–∫–æ–≥–¥–∞|–¥–∞—Ç–∞|–≤—ã–π–¥–µ—Ç|—Ä–µ–ª–∏–∑|–Ω–æ–≤–æ—Å—Ç|–∫—É—Ä—Å|—Ü–µ–Ω–∞|–ø—Ä–æ–≥–Ω–æ–∑|—á—Ç–æ —Ç–∞–∫–æ–µ|–∫—Ç–æ —Ç–∞–∫–æ–π|–Ω–∞–π–¥–∏|—Å—Å—ã–ª–∫–∞|–æ—Ñ–∏—Ü–∏–∞–ª|–∞–¥—Ä–µ—Å|—Ç–µ–ª–µ—Ñ–æ–Ω|"
    r"–ø–æ–≥–æ–¥–∞|—Å–µ–≥–æ–¥–Ω—è|—Å–µ–π—á–∞—Å|—à—Ç—Ä–∞—Ñ|–∑–∞–∫–æ–Ω|—Ç—Ä–µ–Ω–¥|–∫–æ—Ç–∏—Ä–æ–≤–∫|–æ–±–∑–æ—Ä|—Ä–∞—Å–ø–∏—Å–∞–Ω–∏|–∑–∞–ø—É—Å–∫|update|–Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è)",
    re.IGNORECASE
)
_CAPABILITY_RE = re.compile(
    r"(–º–æ–∂(–µ—à—å|–Ω–æ).{0,10}(–∞–Ω–∞–ª–∏–∑(–∏—Ä–æ–≤–∞—Ç—å)?|—Ä–∞—Å–ø–æ–∑–Ω–∞–≤(–∞—Ç—å|–∞–Ω–∏–µ)).{0,10}(—Ñ–æ—Ç–æ|–∫–∞—Ä—Ç–∏–Ω–∫|–∏–∑–æ–±—Ä–∞–∂–µ–Ω|image|picture)|"
    r"–∞–Ω–∞–ª–∏–∑(–∏—Ä–æ–≤–∞—Ç—å)?.{0,8}(—Ñ–æ—Ç–æ|–∫–∞—Ä—Ç–∏–Ω–∫|–∏–∑–æ–±—Ä–∞–∂–µ–Ω)|"
    r"(–º–æ–∂(–µ—à—å|–Ω–æ).{0,10})?(–∞–Ω–∞–ª–∏–∑|—Ä–∞–±–æ—Ç–∞—Ç—å).{0,6}—Å.{0,6}–≤–∏–¥–µ–æ)",
    re.IGNORECASE
)

# === INTENT: —Ä–∞—Å–ø–æ–∑–Ω–∞—ë–º –ø—Ä–æ—Å—å–±—ã –±–µ–∑ –∫–æ–º–∞–Ω–¥ ===
_IMG_WORDS = r"(–∫–∞—Ä—Ç–∏–Ω\w+|–∏–∑–æ–±—Ä–∞–∂–µ–Ω\w+|–ª–æ–≥–æ—Ç–∏–ø\w+|–∏–∫–æ–Ω–∫\w+|–ø–æ—Å—Ç–µ—Ä\w*|image|picture|logo|icon|banner)"
_VID_WORDS = r"(–≤–∏–¥–µ–æ|—Ä–æ–ª–∏–∫\w*|–∫–ª–∏–ø\w*|–∞–Ω–∏–º–∞—Ü–∏\w*|shorts|reel|clip|video)"
_VERBS     = r"(—Å–¥–µ–ª–∞–π|—Å–æ–∑–¥–∞–π|—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π|–Ω–∞—Ä–∏—Å—É–π|—Å—Ñ–æ—Ä–º–∏—Ä—É–π|—Å–æ–±–µ—Ä–∏|—Å–Ω–∏–º–∏|—Å–æ—Ç–≤–æ—Ä|—Ö–æ—á—É|–Ω—É–∂–Ω–æ|–Ω–∞–¥–æ|please|make|generate|create)"

def detect_media_intent(text: str):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç ('image'|'video'|None, prompt)
    –ü–æ–∫—Ä—ã–≤–∞–µ—Ç:
      - "—Å–æ–∑–¥–∞–π –≤–∏–¥–µ–æ –∑–∞–∫–∞—Ç –Ω–∞ –°–∞–º—É–∏..."
      - "—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É –ª–æ–≥–æ—Ç–∏–ø Cozy Asia..."
      - "video ..." / "img ..." –±–µ–∑ —Å–ª—ç—à–µ–π
    """
    if not text:
        return None, ""
    t = text.strip()
    tl = t.lower()

    prefixes_video = [
        "—Å–æ–∑–¥–∞–π –≤–∏–¥–µ–æ", "—Å–¥–µ–ª–∞–π –≤–∏–¥–µ–æ", "—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π –≤–∏–¥–µ–æ", "—Å–Ω–∏–º–∏ –≤–∏–¥–µ–æ",
        "create video", "generate video", "make video", "video "
    ]
    for p in prefixes_video:
        if tl.startswith(p):
            return "video", t[len(p):].strip(" :‚Äî-\"‚Äú‚Äù'¬´¬ª")

    prefixes_image = [
        "—Å–æ–∑–¥–∞–π –∫–∞—Ä—Ç–∏–Ω–∫—É", "—Å–¥–µ–ª–∞–π –∫–∞—Ä—Ç–∏–Ω–∫—É", "—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É", "–Ω–∞—Ä–∏—Å—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É",
        "—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "—Å–æ–∑–¥–∞–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "img ", "image ", "picture "
    ]
    for p in prefixes_image:
        if tl.startswith(p):
            return "image", t[len(p):].strip(" :‚Äî-\"‚Äú‚Äù'¬´¬ª")

    if re.search(_VID_WORDS, tl) and re.search(_VERBS, tl):
        prompt = re.sub(_VID_WORDS, "", tl)
        prompt = re.sub(_VERBS, "", prompt)
        return "video", prompt.strip(" :‚Äî-\"‚Äú‚Äù'¬´¬ª")

    if re.search(_IMG_WORDS, tl) and re.search(_VERBS, tl):
        prompt = re.sub(_IMG_WORDS, "", tl)
        prompt = re.sub(_VERBS, "", prompt)
        return "image", prompt.strip(" :‚Äî-\"‚Äú‚Äù'¬´¬ª")

    return None, ""

def is_smalltalk(text: str) -> bool:
    return bool(_SMALLTALK_RE.search(text.strip()))
def should_browse(text: str) -> bool:
    t = text.strip()
    if is_smalltalk(t):
        return False
    return bool(_NEWSY_RE.search(t) or "?" in t or len(t) > 80)
def is_vision_capability_question(text: str) -> bool:
    return bool(_CAPABILITY_RE.search(text))

# -------- UTILS --------
async def typing(ctx: ContextTypes.DEFAULT_TYPE, chat_id: int):
    try:
        await ctx.bot.send_chat_action(chat_id, action=ChatAction.TYPING)
    except Exception:
        pass

def sniff_image_mime(data: bytes) -> str:
    if data.startswith(b"\xff\xd8"): return "image/jpeg"
    if data.startswith(b"\x89PNG"):  return "image/png"
    if data[:4] == b"RIFF" and b"WEBP" in data[:16]: return "image/webp"
    return "image/jpeg"

def format_sources(items):
    if not items: return ""
    lines = []
    for i, it in enumerate(items, 1):
        title = it.get("title") or it.get("url") or "–ò—Å—Ç–æ—á–Ω–∏–∫"
        url = it.get("url") or ""
        lines.append(f"[{i}] {title} ‚Äî {url}")
    return "\n\n–°—Å—ã–ª–∫–∏:\n" + "\n".join(lines)

def tavily_search(query: str, max_results: int = 5):
    if not tavily: return None, []
    try:
        res = tavily.search(
            query=query, search_depth="advanced", max_results=max_results,
            include_answer=True, include_raw_content=False,
        )
        answer = res.get("answer") or ""
        results = res.get("results") or []
        return answer, results
    except Exception as e:
        log.exception("Tavily error: %s", e)
        return None, []

# -------- OpenAI helpers --------
async def ask_openai_text(user_text: str, web_ctx: str = "") -> str:
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    if web_ctx:
        messages.append({"role": "system", "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –≤–µ–±-–ø–æ–∏—Å–∫–∞:\n{web_ctx}"})
    messages.append({"role": "user", "content": user_text})
    try:
        resp = oai_llm.chat.completions.create(
            model=OPENAI_MODEL, messages=messages, temperature=0.6,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        log.exception("OpenAI chat error: %s", e)
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ (–ª–∏–º–∏—Ç/–∫–ª—é—á). –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ."

async def ask_openai_vision(user_text: str, img_b64: str, mime: str) -> str:
    try:
        resp = oai_llm.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": VISION_SYSTEM_PROMPT},
                {"role": "user", "content": [
                    {"type": "text", "text": user_text or "–û–ø–∏—à–∏, —á—Ç–æ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∏ –∫–∞–∫–æ–π —Ç–∞–º —Ç–µ–∫—Å—Ç."},
                    {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{img_b64}"}}
                ]}
            ],
            temperature=0.4,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        log.exception("Vision error: %s", e)
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–ª–∏–º–∏—Ç/–∫–ª—é—á). –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ."

# -------- STT --------
async def transcribe_audio(buf: BytesIO, filename_hint: str = "audio.ogg") -> str:
    data = buf.getvalue()
    # Deepgram
    if DEEPGRAM_API_KEY:
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                params = {"model": "nova-2", "language": "ru", "smart_format": "true", "punctuate": "true"}
                headers = {
                    "Authorization": f"Token {DEEPGRAM_API_KEY}",
                    "Content-Type": "audio/ogg" if filename_hint.endswith(".ogg") else "application/octet-stream",
                }
                r = await client.post("https://api.deepgram.com/v1/listen", params=params, headers=headers, content=data)
                r.raise_for_status()
                dg = r.json()
                text = (dg.get("results",{}).get("channels",[{}])[0].get("alternatives",[{}])[0].get("transcript","")).strip()
                if text: return text
        except Exception as e:
            log.exception("Deepgram STT error: %s", e)
    # Whisper
    if oai_stt:
        try:
            buf2 = BytesIO(data); buf2.seek(0); setattr(buf2,"name",filename_hint)
            tr = oai_stt.audio.transcriptions.create(model=TRANSCRIBE_MODEL, file=buf2)
            return (tr.text or "").strip()
        except Exception as e:
            log.exception("Whisper STT error: %s", e)
    return ""

# -------- IMAGES (/img) --------
async def cmd_img(update: Update, context: ContextTypes.DEFAULT_TYPE):
    prompt = " ".join(context.args).strip() if context.args else ""
    if not prompt:
        await update.effective_message.reply_text("–ù–∞–ø–∏—à–∏ —Ç–∞–∫: ¬´—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É –ª–æ–≥–æ—Ç–∏–ø Cozy Asia, –Ω–µ–æ–Ω, –ø–ª–æ—Å–∫–∞—è –∏–∫–æ–Ω–∫–∞¬ª")
        return
    try:
        await context.bot.send_chat_action(update.effective_chat.id, ChatAction.UPLOAD_PHOTO)
        resp = oai_img.images.generate(model="gpt-image-1", prompt=prompt, size="1024x1024", n=1)
        b64 = resp.data[0].b64_json
        img_bytes = base64.b64decode(b64)
        await update.effective_message.reply_photo(photo=img_bytes, caption=f"–ì–æ—Ç–æ–≤–æ ‚úÖ\n–ó–∞–ø—Ä–æ—Å: {prompt}")
    except Exception as e:
        log.exception("Images API error: %s", e)
        await update.effective_message.reply_text("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü—Ä–æ–≤–µ—Ä—å OPENAI_IMAGE_KEY (–Ω—É–∂–µ–Ω –æ–±—ã—á–Ω—ã–π OpenAI –∫–ª—é—á).")

# -------- VIDEO (Runway SDK) --------
# –ø—Ä–æ–∫–∏–Ω–µ–º –∫–ª—é—á –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –¥–ª—è SDK
if RUNWAY_API_KEY:
    os.environ["RUNWAY_API_KEY"] = RUNWAY_API_KEY

from runwayml import RunwayML

def _runway_make_video_sync(prompt: str, duration: int = 8) -> bytes:
    """–°–æ–∑–¥–∞—ë—Ç –∑–∞–¥–∞—á—É Runway –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç mp4-–±–∞–π—Ç—ã (–±–ª–æ–∫–∏—Ä—É—é—â–µ)."""
    if not RUNWAY_API_KEY:
        raise RuntimeError("RUNWAY_API_KEY –Ω–µ –∑–∞–¥–∞–Ω")
    client = RunwayML(api_key=RUNWAY_API_KEY)

    task = client.text_to_video.create(
        prompt_text=prompt,   # –í–ê–ñ–ù–û: snake_case
        model="veo3",
        ratio="720:1280",
        duration=duration,
    )
    task_id = task.id
    time.sleep(1)
    task = client.tasks.retrieve(task_id)
    while task.status not in ["SUCCEEDED", "FAILED"]:
        time.sleep(1)
        task = client.tasks.retrieve(task_id)

    if task.status != "SUCCEEDED":
        raise RuntimeError(getattr(task, "error", None) or f"Runway task failed: {task.status}")

    output = getattr(task, "output", None)
    if isinstance(output, list) and output:
        video_url = output[0]
    elif isinstance(output, dict):
        video_url = output.get("url") or output.get("video_url")
    else:
        raise RuntimeError(f"Runway: –Ω–µ –Ω–∞–π–¥–µ–Ω URL —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ output: {output}")

    with httpx.Client(timeout=None) as http:
        r = http.get(video_url)
        r.raise_for_status()
        return r.content

async def cmd_make_video(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # üîí PRO-–≥–µ–π—Ç–∏–Ω–≥ Runway
    if update.effective_user.id not in PREMIUM_USER_IDS:
        await update.effective_message.reply_text(
            "‚ö†Ô∏è Runway –¥–æ—Å—Ç—É–ø–µ–Ω —Ç–æ–ª—å–∫–æ –Ω–∞ PRO-—Ç–∞—Ä–∏—Ñ–µ.\n"
            "–≠—Ç–æ —Å—Ç—É–¥–∏–π–Ω–æ–µ –≤–∏–¥–µ–æ –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞, –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å ‚âà $7."
        )
        return

    prompt = " ".join(context.args).strip()
    if not prompt:
        await update.effective_message.reply_text("–ù–∞–ø–∏—à–∏ —Ç–∞–∫: /video –∑–∞–∫–∞—Ç –Ω–∞ –°–∞–º—É–∏, –¥—Ä–æ–Ω, —Ç—ë–ø–ª—ã–µ —Ü–≤–µ—Ç–∞")
        return

    await update.effective_message.reply_text("üé¨ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ Runway‚Ä¶")
    await context.bot.send_chat_action(update.effective_chat.id, ChatAction.UPLOAD_VIDEO)
    try:
        video_bytes = await asyncio.to_thread(_runway_make_video_sync, prompt, 8)
        await update.effective_message.reply_video(
            video=video_bytes, supports_streaming=True, caption=f"–ì–æ—Ç–æ–≤–æ üé•\n{prompt}"
        )
    except Exception as e:
        msg = str(e)
        if "401" in msg or "Unauthorized" in msg:
            hint = (
                "–ü–æ—Ö–æ–∂–µ, –∫–ª—é—á –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç—Å—è API (401).\n"
                "–ü—Ä–æ–≤–µ—Ä—å:\n"
                "‚Ä¢ –ö–ª—é—á –∏–º–µ–Ω–Ω–æ –∏–∑ dev.runwayml.com ‚Üí API Keys (—Ñ–æ—Ä–º–∞—Ç key_...)\n"
                "‚Ä¢ –í Render –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è —Ä–æ–≤–Ω–æ RUNWAY_API_KEY\n"
                "‚Ä¢ –ü–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è ENV —Å–¥–µ–ª–∞–Ω Deploy\n"
            )
            await update.effective_message.reply_text(f"‚ö†Ô∏è –í–∏–¥–µ–æ –Ω–µ —É–¥–∞–ª–æ—Å—å (401): –ø—Ä–æ–≤–µ—Ä—å –∫–ª—é—á.\n\n{hint}")
        elif "credit" in msg.lower():
            await update.effective_message.reply_text("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤ Runway –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.")
        else:
            await update.effective_message.reply_text(f"‚ö†Ô∏è –í–∏–¥–µ–æ –Ω–µ —É–¥–∞–ª–æ—Å—å: {e}")
        log.exception("Runway video error: %s", e)

# -------- –ê–≤—Ç–æ–≤—ã–∑–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±–µ–∑ –∫–æ–º–∞–Ω–¥ --------
async def _call_handler_with_prompt(handler, update: Update, context: ContextTypes.DEFAULT_TYPE, prompt: str):
    old_args = getattr(context, "args", None)
    try:
        context.args = [prompt]
        await handler(update, context)
    finally:
        context.args = old_args

# -------- STATIC TEXTS --------
START_TEXT = (
    "–ü—Ä–∏–≤–µ—Ç! –Ø –≥–æ—Ç–æ–≤. –ß–µ–º –ø–æ–º–æ—á—å?\n\n"
    "–ú–æ–∂–µ—à—å –ø–∏—Å–∞—Ç—å –ø–æ-—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏:\n"
    "‚Ä¢ ¬´—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É –ª–æ–≥–æ—Ç–∏–ø Cozy Asia‚Ä¶¬ª\n"
    "‚Ä¢ ¬´—Å–æ–∑–¥–∞–π –≤–∏–¥–µ–æ –∑–∞–∫–∞—Ç –Ω–∞ –°–∞–º—É–∏, –¥—Ä–æ–Ω‚Ä¶¬ª\n\n"
    "–¢–∞–∫–∂–µ —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ–º–∞–Ω–¥—ã:\n"
    "üñº /img <–æ–ø–∏—Å–∞–Ω–∏–µ>  ‚Ä¢  üé¨ /video <–æ–ø–∏—Å–∞–Ω–∏–µ>\n"
)

MODES_TEXT = (
    "‚öôÔ∏è *–†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã*\n"
    "‚Ä¢ üí¨ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π ‚Äî –æ–±—ã—á–Ω—ã–π –¥–∏–∞–ª–æ–≥.\n"
    "‚Ä¢ üß† –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å ‚Äî —Ñ–∞–∫—Ç—ã/–∏—Å—Ç–æ—á–Ω–∏–∫–∏, —Å–≤–æ–¥–∫–∏.\n"
    "‚Ä¢ ‚úçÔ∏è –†–µ–¥–∞–∫—Ç–æ—Ä ‚Äî –ø—Ä–∞–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞, —Å—Ç–∏–ª—å, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞.\n"
    "‚Ä¢ üìä –ê–Ω–∞–ª–∏—Ç–∏–∫ ‚Äî —Ñ–æ—Ä–º—É–ª—ã, —Ç–∞–±–ª–∏—Ü—ã, —Ä–∞—Å—á—ë—Ç–Ω—ã–µ —à–∞–≥–∏.\n"
    "‚Ä¢ üñºÔ∏è –í–∏–∑—É–∞–ª—å–Ω—ã–π ‚Äî –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, OCR, —Å—Ö–µ–º—ã.\n"
    "‚Ä¢ üéôÔ∏è –ì–æ–ª–æ—Å ‚Äî —Ä–∞—Å–ø–æ–∑–Ω–∞—é –∞—É–¥–∏–æ –∏ –æ—Ç–≤–µ—á–∞—é –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é.\n\n"
    "_–ü–∏—à–∏ –∑–∞–¥–∞—á—É ‚Äî —è —Å–∞–º –≤—ã–±–µ—Ä—É –Ω—É–∂–Ω—ã–π —Ä–µ–∂–∏–º._"
)

EXAMPLES_TEXT = (
    "üß© *–ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤*\n"
    "‚Ä¢ ¬´–°–¥–µ–ª–∞–π –∫–æ–Ω—Å–ø–µ–∫—Ç –≥–ª–∞–≤—ã 3 –∏ –≤—ã–¥–µ–ª–∏ —Ñ–æ—Ä–º—É–ª—ã¬ª\n"
    "‚Ä¢ ¬´–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π CSV, –Ω–∞–π–¥–∏ —Ç—Ä–µ–Ω–¥—ã –∏ —Å–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–∏–π –≤—ã–≤–æ–¥¬ª\n"
    "‚Ä¢ ¬´–°–æ—Å—Ç–∞–≤—å –ø–∏—Å—å–º–æ –∫–ª–∏–µ–Ω—Ç—É, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ –ø–æ –¥–µ–ª—É¬ª\n"
    "‚Ä¢ ¬´–°—É–º–º–∏—Ä—É–π —Å—Ç–∞—Ç—å—é –∏–∑ —Å—Å—ã–ª–∫–∏ –∏ –¥–∞–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏¬ª\n"
    "‚Ä¢ ¬´–û–ø–∏—à–∏ —Ç–µ–∫—Å—Ç –Ω–∞ —Ñ–æ—Ç–æ –∏ –∏–∑–≤–ª–µ–∫–∏ —Ç–∞–±–ª–∏—Ü—É¬ª"
)

# -------- UI / KEYBOARD --------
main_kb = ReplyKeyboardMarkup(
    [
        [KeyboardButton("üß≠ –ú–µ–Ω—é", web_app=WebAppInfo(url=WEB_ROOT))],
        [KeyboardButton("‚öôÔ∏è –†–µ–∂–∏–º—ã"), KeyboardButton("üß© –ü—Ä–∏–º–µ—Ä—ã")],
        [KeyboardButton("‚≠ê –ü–æ–¥–ø–∏—Å–∫–∞", web_app=WebAppInfo(url=f"{WEB_ROOT}/premium.html"))],
    ],
    resize_keyboard=True
)

# -------- HANDLERS --------
async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if BANNER_URL:
        try:
            await update.effective_message.reply_photo(BANNER_URL)
        except Exception:
            pass
    await update.effective_message.reply_text(START_TEXT, reply_markup=main_kb, disable_web_page_preview=True)

async def cmd_modes(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.effective_message.reply_text(MODES_TEXT, disable_web_page_preview=True, parse_mode="Markdown")

async def cmd_examples(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.effective_message.reply_text(EXAMPLES_TEXT, disable_web_page_preview=True, parse_mode="Markdown")

# NEW: –±—ã—Å—Ç—Ä–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∫–ª—é—á–∞ Runway
async def cmd_diag_runway(update: Update, context: ContextTypes.DEFAULT_TYPE):
    key = RUNWAY_API_KEY
    lines = [f"RUNWAY_API_KEY: {'‚úÖ –Ω–∞–π–¥–µ–Ω' if key else '‚ùå –Ω–µ—Ç'}"]
    if key:
        lines.append(f"–§–æ—Ä–º–∞—Ç: {'ok' if key.startswith('key_') else '–Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å key_'}")
        lines.append(f"–î–ª–∏–Ω–∞: {len(key)}")
        try:
            _ = RunwayML(api_key=key)
            lines.append("SDK –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω ‚úÖ")
        except Exception as e:
            lines.append(f"SDK error: {e}")
    pro_list = ", ".join(map(str, sorted(PREMIUM_USER_IDS))) or "‚Äî"
    lines.append(f"PRO (PREMIUM_USER_IDS): {pro_list}")
    await update.message.reply_text("\n".join(lines))

async def handle_web_app_data(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = update.effective_message
    wad = getattr(msg, "web_app_data", None)
    if not wad:
        return
    raw = wad.data or ""
    try:
        payload = json.loads(raw) if raw.strip().startswith("{") else {"type": raw}
    except Exception:
        payload = {"type": str(raw)}

    ptype = (payload.get("type") or "").strip().lower()
    log.info("web_app_data: %s", payload)

    if ptype in ("help_from_webapp", "help", "question"):
        await msg.reply_text("üßë‚Äçüíª –ü–æ–¥–¥–µ—Ä–∂–∫–∞ GPT-5 PRO.\n–ù–∞–ø–∏—à–∏ –∑–¥–µ—Å—å —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å ‚Äî –æ—Ç–≤–µ—á—É –≤ —á–∞—Ç–µ.\n\n–¢–∞–∫–∂–µ –º–æ–∂–Ω–æ –Ω–∞ –ø–æ—á—Ç—É: sale.rielt@bk.ru")
        return

    if ptype in ("plan_from_webapp", "plan", "subscribe", "subscription"):
        kb = ReplyKeyboardMarkup(
            [[KeyboardButton("‚≠ê –û—Ç–∫—Ä—ã—Ç—å –ø–æ–¥–ø–∏—Å–∫—É", web_app=WebAppInfo(url=f"{WEB_ROOT}/premium.html"))]],
            resize_keyboard=True, one_time_keyboard=True
        )
        await msg.reply_text("–û—Ñ–æ—Ä–º–∏—Ç—å –ø–æ–¥–ø–∏—Å–∫—É –º–æ–∂–Ω–æ –ø–æ –∫–Ω–æ–ø–∫–µ –Ω–∏–∂–µ. ‚§µÔ∏è", reply_markup=kb)
        return

    await msg.reply_text("–û—Ç–∫—Ä—ã–ª –±–æ—Ç–∞. –ß–µ–º –ø–æ–º–æ—á—å?", reply_markup=main_kb)

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (update.message.text or "").strip()
    chat_id = update.effective_chat.id

    # === –∞–≤—Ç–æ-—Ä–µ–∂–∏–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±–µ–∑ –∫–æ–º–∞–Ω–¥ ===
    intent, prompt = detect_media_intent(text)
    if intent == "image" and prompt:
        await _call_handler_with_prompt(cmd_img, update, context, prompt); return
    if intent == "video" and prompt:
        await _call_handler_with_prompt(cmd_make_video, update, context, prompt); return

    lower = text.lower()
    if lower in ("‚öôÔ∏è —Ä–µ–∂–∏–º—ã", "—Ä–µ–∂–∏–º—ã", "/modes"):
        await cmd_modes(update, context); return
    if lower in ("üß© –ø—Ä–∏–º–µ—Ä—ã", "–ø—Ä–∏–º–µ—Ä—ã", "/examples"):
        await cmd_examples(update, context); return

    if is_vision_capability_question(text):
        await update.message.reply_text(
            "–î–∞ ‚Äî –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –ø–æ–º–æ–≥–∞—é —Å –≤–∏–¥–µ–æ –ø–æ –∫–∞–¥—Ä–∞–º, –∞ –µ—â—ë —Ä–∞—Å–ø–æ–∑–Ω–∞—é –≥–æ–ª–æ—Å. ‚úÖ\n\n"
            "‚Ä¢ –§–æ—Ç–æ/—Å–∫—Ä–∏–Ω—à–æ—Ç—ã: JPG/PNG/WebP (–¥–æ ~10 –ú–ë)\n"
            "‚Ä¢ –í–∏–¥–µ–æ: –ø—Ä–∏—à–ª–∏ 1‚Äì3 –∫–ª—é—á–µ–≤—ã—Ö –∫–∞–¥—Ä–∞ (—Å–∫—Ä–∏–Ω—à–æ—Ç–∞)"
        ); return

    await typing(context, chat_id)

    if is_smalltalk(text):
        reply = await ask_openai_text(text)
        await update.message.reply_text(reply); return

    web_ctx = ""
    sources = []
    if should_browse(text):
        ans, results = tavily_search(text, max_results=5)
        sources = results or []
        ctx_lines = []
        if ans: ctx_lines.append(f"–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ–∏—Å–∫–æ–º: {ans}")
        for i, it in enumerate(sources, 1):
            ctx_lines.append(f"[{i}] {it.get('title','')}: {it.get('url','')}")
        web_ctx = "\n".join(ctx_lines)

    answer = await ask_openai_text(text, web_ctx=web_ctx)
    if sources:
        answer += "\n\n" + "\n".join([f"[{i+1}] {s.get('title','')} ‚Äî {s.get('url','')}" for i, s in enumerate(sources)])
    await update.message.reply_text(answer, disable_web_page_preview=False)

async def _handle_image_bytes(update: Update, context: ContextTypes.DEFAULT_TYPE, data: bytes, user_text: str):
    mime = sniff_image_mime(data)
    img_b64 = base64.b64encode(data).decode("ascii")
    answer = await ask_openai_vision(user_text, img_b64, mime)
    await update.message.reply_text(answer, disable_web_page_preview=True)

async def on_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await typing(context, chat_id)
    photo = update.message.photo[-1]
    file = await context.bot.get_file(photo.file_id)
    buf = BytesIO(); await file.download_to_memory(buf)
    user_text = (update.message.caption or "").strip()
    await _handle_image_bytes(update, context, buf.getvalue(), user_text)

async def on_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await typing(context, chat_id)
    doc = update.message.document
    mime = (doc.mime_type or "").lower()
    if mime.startswith("image/"):
        file = await context.bot.get_file(doc.file_id)
        buf = BytesIO(); await file.download_to_memory(buf)
        user_text = (update.message.caption or "").strip()
        await _handle_image_bytes(update, context, buf.getvalue(), user_text)
    else:
        await update.message.reply_text("–§–∞–π–ª –ø–æ–ª—É—á–∏–ª. –ï—Å–ª–∏ —ç—Ç–æ PDF/–¥–æ–∫—É–º–µ–Ω—Ç ‚Äî –ø—Ä–∏—à–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ —É–∫–∞–∂–∏, —á—Ç–æ –∏–∑–≤–ª–µ—á—å.")

async def on_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await typing(context, chat_id)
    voice = update.message.voice
    file = await context.bot.get_file(voice.file_id)
    buf = BytesIO(); await file.download_to_memory(buf)
    text = await transcribe_audio(buf, filename_hint="audio.ogg")
    if not text:
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑."); return
    prefix = f"üó£Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–ª: ¬´{text}¬ª\n\n"
    web_ctx = ""
    sources = []
    if should_browse(text):
        ans, results = tavily_search(text, max_results=5)
        sources = results or []
        ctx_lines = []
        if ans: ctx_lines.append(f"–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ–∏—Å–∫–æ–º: {ans}")
        for i, it in enumerate(sources, 1):
            ctx_lines.append(f"[{i}] {it.get('title','')}: {it.get('url','')}")
        web_ctx = "\n".join(ctx_lines)
    answer = await ask_openai_text(text, web_ctx=web_ctx)
    if sources:
        answer += "\n\n" + "\n".join([f"[{i+1}] {s.get('title','')} ‚Äî {s.get('url','')}" for i, s in enumerate(sources)])
    await update.message.reply_text(prefix + answer, disable_web_page_preview=False)

async def on_audio(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await typing(context, chat_id)
    audio = update.message.audio
    file = await context.bot.get_file(audio.file_id)
    buf = BytesIO(); await file.download_to_memory(buf)
    filename = (audio.file_name or "audio.mp3")
    text = await transcribe_audio(buf, filename_hint=filename)
    if not text:
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∞—É–¥–∏–æ. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑."); return
    prefix = f"üó£Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–ª: ¬´{text}¬ª\n\n"
    web_ctx = ""
    sources = []
    if should_browse(text):
        ans, results = tavily_search(text, max_results=5)
        sources = results or []
        ctx_lines = []
        if ans: ctx_lines.append(f"–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ–∏—Å–∫–æ–º: {ans}")
        for i, it in enumerate(sources, 1):
            ctx_lines.append(f"[{i}] {it.get('title','')}: {it.get('url','')}")
        web_ctx = "\n".join(ctx_lines)
    answer = await ask_openai_text(text, web_ctx=web_ctx)
    if sources:
        answer += "\n\n" + "\n".join([f"[{i+1}] {s.get('title','')} ‚Äî {s.get('url','')}" for i, s in enumerate(sources)])
    await update.message.reply_text(prefix + answer, disable_web_page_preview=False)

async def on_video(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–î–∞, –ø–æ–º–æ–≥—É —Å –≤–∏–¥–µ–æ: –ø—Ä–∏—à–ª–∏ 1‚Äì3 –∫–ª—é—á–µ–≤—ã—Ö –∫–∞–¥—Ä–∞ (—Å–∫—Ä–∏–Ω—à–æ—Ç–∞) ‚Äî –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø–æ –∫–∞–¥—Ä–∞–º –∏ –æ—Ç–≤–µ—á—É –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é. üìΩÔ∏è")

# -------- BOOTSTRAP --------
def build_app():
    app = ApplicationBuilder().token(BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("modes", cmd_modes))
    app.add_handler(CommandHandler("examples", cmd_examples))
    app.add_handler(CommandHandler("diag_runway", cmd_diag_runway))  # NEW

    # –ö–æ–º–∞–Ω–¥—ã —Ç–æ–∂–µ –¥–æ—Å—Ç—É–ø–Ω—ã
    app.add_handler(CommandHandler("img", cmd_img))
    app.add_handler(CommandHandler("video", cmd_make_video))

    app.add_handler(MessageHandler(filters.StatusUpdate.WEB_APP_DATA, handle_web_app_data))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))
    app.add_handler(MessageHandler(filters.PHOTO, on_photo))
    app.add_handler(MessageHandler(filters.Document.IMAGE, on_document))
    app.add_handler(MessageHandler(filters.VOICE, on_voice))
    app.add_handler(MessageHandler(filters.AUDIO, on_audio))
    app.add_handler(MessageHandler(filters.VIDEO, on_video))
    return app

def run_webhook(app):
    url_path = f"webhook/{BOT_TOKEN}"
    webhook_url = f"{PUBLIC_URL.rstrip('/')}/{url_path}"

    log.info("Starting webhook on 0.0.0.0:%s  ->  %s", PORT, webhook_url)
    app.run_webhook(
        listen="0.0.0.0",
        port=PORT,
        url_path=url_path,
        webhook_url=webhook_url,
        secret_token=WEBHOOK_SECRET or None,
        drop_pending_updates=True,
    )

def main():
    app = build_app()
    run_webhook(app)

# –∫–æ—Ä–æ—Ç–∫–∏–µ –∞–ª–∏–∞—Å—ã, —á—Ç–æ–±—ã —Å–æ–≤–ø–∞–ª–æ —Å handler-–∏–º–µ–Ω–∞–º–∏
cmd_start = cmd_start if 'cmd_start' in globals() else None
cmd_modes = cmd_modes if 'cmd_modes' in globals() else None
cmd_examples = cmd_examples if 'cmd_examples' in globals() else None

if __name__ == "__main__":
    main()

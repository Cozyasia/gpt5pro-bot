# -*- coding: utf-8 -*-
import os
import re
import base64
import logging
from io import BytesIO

import httpx
from telegram import Update, ReplyKeyboardMarkup, KeyboardButton, WebAppInfo
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
)
from telegram.constants import ChatAction

# ========== LOGGING ==========
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
)
log = logging.getLogger("gpt-bot")

# ========== ENV ==========
BOT_TOKEN        = os.environ.get("BOT_TOKEN", "").strip()
PUBLIC_URL       = os.environ.get("PUBLIC_URL", "").strip()       # https://<subdomain>.onrender.com (ÑÐµÑ€Ð²ÐµÑ€ Ð±Ð¾Ñ‚Ð°)
OPENAI_API_KEY   = os.environ.get("OPENAI_API_KEY", "").strip()
OPENAI_MODEL     = os.environ.get("OPENAI_MODEL", "gpt-4o-mini").strip()
WEBHOOK_SECRET   = os.environ.get("WEBHOOK_SECRET", "").strip()
BANNER_URL       = os.environ.get("BANNER_URL", "").strip()       # Ð½ÐµÐ¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ (ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐ° Ð¿Ñ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ñ)
TAVILY_API_KEY   = os.environ.get("TAVILY_API_KEY", "").strip()
DEEPGRAM_API_KEY = os.environ.get("DEEPGRAM_API_KEY", "").strip()
TRANSCRIBE_MODEL = os.environ.get("OPENAI_TRANSCRIBE_MODEL", "whisper-1").strip()
WEBAPP_URL       = os.environ.get("WEBAPP_URL", "").strip().rstrip("/")  # Ð´Ð¾Ð¼ÐµÐ½ Ð¼Ð¸Ð½Ð¸-Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ! (Ð½Ðµ ÑÐµÑ€Ð²ÐµÑ€ Ð±Ð¾Ñ‚Ð°)
WEBAPP_PREMIUM_PATH = os.environ.get("WEBAPP_PREMIUM_PATH", "/premium").strip()  # Ð´Ð»Ñ SPA Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿Ð¾ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ "#/premium"
PORT             = int(os.environ.get("PORT", "10000"))

if not BOT_TOKEN:
    raise RuntimeError("ENV BOT_TOKEN is required")
if not PUBLIC_URL or not PUBLIC_URL.startswith("http"):
    raise RuntimeError("ENV PUBLIC_URL must look like https://xxx.onrender.com")

# ========== OPENAI / Tavily ==========
from openai import OpenAI
oai = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

try:
    if TAVILY_API_KEY:
        from tavily import TavilyClient
        tavily = TavilyClient(api_key=TAVILY_API_KEY)
    else:
        tavily = None
except Exception:
    tavily = None

# ========== PROMPTS ==========
SYSTEM_PROMPT = (
    "Ð¢Ñ‹ Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ñ‹Ð¹ Ð¸ Ð»Ð°ÐºÐ¾Ð½Ð¸Ñ‡Ð½Ñ‹Ð¹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼. "
    "ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð¿Ð¾ ÑÑƒÑ‚Ð¸, ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€ÑƒÐ¹ ÑÐ¿Ð¸ÑÐºÐ°Ð¼Ð¸/ÑˆÐ°Ð³Ð°Ð¼Ð¸, Ð½Ðµ Ð²Ñ‹Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹ Ñ„Ð°ÐºÑ‚Ñ‹. "
    "Ð•ÑÐ»Ð¸ ÑÑÑ‹Ð»Ð°ÐµÑˆÑŒÑÑ Ð½Ð° Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸ â€” Ð² ÐºÐ¾Ð½Ñ†Ðµ Ð´Ð°Ð¹ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº ÑÑÑ‹Ð»Ð¾Ðº."
)

VISION_SYSTEM_PROMPT = (
    "Ð¢Ñ‹ Ñ‡Ñ‘Ñ‚ÐºÐ¾ Ð¾Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÑˆÑŒ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹: Ð¾Ð±ÑŠÐµÐºÑ‚Ñ‹, Ñ‚ÐµÐºÑÑ‚, ÑÑ…ÐµÐ¼Ñ‹, Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¸. "
    "ÐÐµ Ð¸Ð´ÐµÐ½Ñ‚Ð¸Ñ„Ð¸Ñ†Ð¸Ñ€ÑƒÐ¹ Ð»Ð¸Ñ‡Ð½Ð¾ÑÑ‚Ð¸ Ð»ÑŽÐ´ÐµÐ¹ Ð¸ Ð½Ðµ Ð¿Ð¸ÑˆÐ¸ Ð¸Ð¼ÐµÐ½Ð°, ÐµÑÐ»Ð¸ Ð¾Ð½Ð¸ Ð½Ðµ Ð½Ð°Ð¿ÐµÑ‡Ð°Ñ‚Ð°Ð½Ñ‹ Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸."
)

VISION_CAPABILITY_HELP = (
    "Ð”Ð° â€” Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¸ Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÑŽ Ñ Ð²Ð¸Ð´ÐµÐ¾ Ð¿Ð¾ ÐºÐ°Ð´Ñ€Ð°Ð¼, Ð° ÐµÑ‰Ñ‘ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°ÑŽ Ð³Ð¾Ð»Ð¾Ñ. âœ…\n\n"
    "â€¢ Ð¤Ð¾Ñ‚Ð¾/ÑÐºÑ€Ð¸Ð½ÑˆÐ¾Ñ‚Ñ‹: JPG/PNG/WebP (Ð´Ð¾ ~10 ÐœÐ‘) â€” Ð¾Ð¿Ð¸ÑˆÑƒ, Ð¿Ñ€Ð¾Ñ‡Ð¸Ñ‚Ð°ÑŽ Ñ‚ÐµÐºÑÑ‚, Ñ€Ð°Ð·Ð±ÐµÑ€Ñƒ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¸.\n"
    "â€¢ Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹/PDF: Ð¿Ñ€Ð¸ÑˆÐ»Ð¸ ÐºÐ°Ðº *Ñ„Ð°Ð¹Ð»*, Ð¸Ð·Ð²Ð»ÐµÐºÑƒ Ñ‚ÐµÐºÑÑ‚/Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹.\n"
    "â€¢ Ð’Ð¸Ð´ÐµÐ¾: Ð¿Ñ€Ð¸ÑˆÐ»Ð¸ 1â€“3 ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… ÐºÐ°Ð´Ñ€Ð° (ÑÐºÑ€Ð¸Ð½ÑˆÐ¾Ñ‚Ð°) â€” Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ Ð¿Ð¾ ÐºÐ°Ð´Ñ€Ð°Ð¼.\n"
    "â€¢ Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ñ‹Ðµ/Ð°ÑƒÐ´Ð¸Ð¾: Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°ÑŽ Ñ€ÐµÑ‡ÑŒ Ð¸ Ð¾Ñ‚Ð²ÐµÑ‡Ñƒ Ð¿Ð¾ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸ÑŽ."
)

# ÐšÑ€Ð°ÑÐ¸Ð²Ð¾Ðµ Ð¿Ñ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ (Ð¾Ð´Ð½Ð¾, Ð±ÐµÐ· Â«Ð¿Ð¾Ð´ÑÐºÐ°Ð·Ð¾ÐºÂ» Ð½Ð¸Ð¶Ðµ)
START_TEXT = (
    "**GPT-5 PRO â€” ÑƒÐ¼Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð½Ð° Ð±Ð°Ð·Ðµ ChatGPT ðŸ¤–**\n"
    "ÐžÑ‚Ð²ÐµÑ‡Ð°ÑŽ Ð¿Ð¾ Ð´ÐµÐ»Ñƒ, *Ð¸Ñ‰Ñƒ Ñ„Ð°ÐºÑ‚Ñ‹ Ð² Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ðµ* ðŸŒ, *Ð¿Ð¾Ð½Ð¸Ð¼Ð°ÑŽ Ñ„Ð¾Ñ‚Ð¾* ðŸ–¼ï¸ Ð¸ *Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°ÑŽ Ð³Ð¾Ð»Ð¾Ñ* ðŸŽ™ï¸.\n\n"
    "**Ð§Ñ‚Ð¾ ÑƒÐ¼ÐµÑŽ:**\n"
    "â€¢ âœï¸ Ð­ÑÑÐµ/Ñ€ÐµÑ„ÐµÑ€Ð°Ñ‚Ñ‹/Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹, Ð¿Ð»Ð°Ð½Ñ‹, Ð¿Ñ€Ð°Ð²ÐºÐ¸.\n"
    "â€¢ ðŸ§® Ð Ð°ÑÑ‡Ñ‘Ñ‚Ñ‹, Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ñ‹, Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹, Ð½Ð°Ð±Ñ€Ð¾ÑÐºÐ¸ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð².\n"
    "â€¢ ðŸ“š ÐžÐ±ÑŠÑÑÐ½ÐµÐ½Ð¸Ñ, ÐºÐ¾Ð½ÑÐ¿ÐµÐºÑ‚Ñ‹, Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ñ‹.\n"
    "â€¢ ðŸ”Ž ÐŸÐ¾Ð¸ÑÐº Ð² ÑÐµÑ‚Ð¸ ÑÐ¾ *ÑÑÑ‹Ð»ÐºÐ°Ð¼Ð¸*.\n"
    "â€¢ ðŸ–¼ï¸ Ð¤Ð¾Ñ‚Ð¾: Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ, OCR, ÑÑ…ÐµÐ¼Ñ‹/Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¸.\n"
    "â€¢ ðŸŽ§ Ð“Ð¾Ð»Ð¾Ñ/Ð°ÑƒÐ´Ð¸Ð¾: Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°ÑŽ Ð¸ Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÑŽ Ð¿Ð¾ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸ÑŽ.\n"
    "â€¢ ðŸ’¼ Ð Ð°Ð±Ð¾Ñ‚Ð°: Ð¿Ð¸ÑÑŒÐ¼Ð°, Ð±Ñ€Ð¸Ñ„Ñ‹, Ñ‡ÐµÐº-Ð»Ð¸ÑÑ‚Ñ‹, Ð¸Ð´ÐµÐ¸.\n\n"
    "ÐšÐ½Ð¾Ð¿ÐºÐ¸: ðŸ§­ ÐœÐµÐ½ÑŽ Â· âš™ï¸ Ð ÐµÐ¶Ð¸Ð¼Ñ‹ Â· ðŸ§© ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Â· â­ ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°"
)

MODES_TEXT = (
    "âš™ï¸ **Ð ÐµÐ¶Ð¸Ð¼Ñ‹ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹**\n"
    "â€¢ ðŸ’¬ Ð£Ð½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ñ‹Ð¹ â€” Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³.\n"
    "â€¢ ðŸ§  Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ â€” Ñ„Ð°ÐºÑ‚Ñ‹/Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸, ÑÐ²Ð¾Ð´ÐºÐ¸.\n"
    "â€¢ âœï¸ Ð ÐµÐ´Ð°ÐºÑ‚Ð¾Ñ€ â€” Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ñ‚ÐµÐºÑÑ‚Ð°, ÑÑ‚Ð¸Ð»ÑŒ, ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð°.\n"
    "â€¢ ðŸ“Š ÐÐ½Ð°Ð»Ð¸Ñ‚Ð¸Ðº â€” Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ñ‹, Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹, Ñ€Ð°ÑÑ‡Ñ‘Ñ‚Ð½Ñ‹Ðµ ÑˆÐ°Ð³Ð¸.\n"
    "â€¢ ðŸ–¼ï¸ Ð’Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ â€” Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹, OCR, ÑÑ…ÐµÐ¼Ñ‹.\n"
    "â€¢ ðŸŽ™ï¸ Ð“Ð¾Ð»Ð¾Ñ â€” Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°ÑŽ Ð°ÑƒÐ´Ð¸Ð¾ Ð¸ Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÑŽ Ð¿Ð¾ ÑÑƒÑ‚Ð¸.\n\n"
    "Ð’Ñ‹Ð±Ð¸Ñ€Ð°Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸ÐµÐ¼ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ ÑÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€ÑƒÐ¹ Ð·Ð°Ð´Ð°Ñ‡Ñƒ ðŸ˜‰"
)

EXAMPLES_TEXT = (
    "ðŸ§© **ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²**\n"
    "â€¢ Â«Ð¡Ð´ÐµÐ»Ð°Ð¹ ÐºÐ¾Ð½ÑÐ¿ÐµÐºÑ‚ Ð³Ð»Ð°Ð²Ñ‹ 3 Ð¸ Ð²Ñ‹Ð´ÐµÐ»Ð¸ Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ñ‹Â»\n"
    "â€¢ Â«ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ CSV, Ð½Ð°Ð¹Ð´Ð¸ Ñ‚Ñ€ÐµÐ½Ð´Ñ‹ Ð¸ ÑÐ´ÐµÐ»Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¹ Ð²Ñ‹Ð²Ð¾Ð´Â»\n"
    "â€¢ Â«Ð¡Ð¾ÑÑ‚Ð°Ð²ÑŒ Ð¿Ð¸ÑÑŒÐ¼Ð¾ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñƒ, Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ð¾ Ð¸ Ð¿Ð¾ Ð´ÐµÐ»ÑƒÂ»\n"
    "â€¢ Â«Ð¡ÑƒÐ¼Ð¼Ð¸Ñ€ÑƒÐ¹ ÑÑ‚Ð°Ñ‚ÑŒÑŽ Ð¸Ð· ÑÑÑ‹Ð»ÐºÐ¸ Ð¸ Ð´Ð°Ð¹ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸Â»\n"
    "â€¢ Â«ÐžÐ¿Ð¸ÑˆÐ¸ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° Ñ„Ð¾Ñ‚Ð¾ Ð¸ Ð¸Ð·Ð²Ð»ÐµÐºÐ¸ Ñ‚Ð°Ð±Ð»Ð¸Ñ†ÑƒÂ»"
)

# ========== HEURISTICS ==========
_SMALLTALK_RE = re.compile(
    r"^(Ð¿Ñ€Ð¸Ð²ÐµÑ‚|Ð·Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹|Ð´Ð¾Ð±Ñ€Ñ‹Ð¹\s*(Ð´ÐµÐ½ÑŒ|Ð²ÐµÑ‡ÐµÑ€|ÑƒÑ‚Ñ€Ð¾)|Ñ…Ð¸|hi|hello|Ñ…ÐµÐ»Ð»Ð¾|ÐºÐ°Ðº Ð´ÐµÐ»Ð°|ÑÐ¿Ð°ÑÐ¸Ð±Ð¾|Ð¿Ð¾ÐºÐ°)\b",
    re.IGNORECASE
)
_NEWSY_RE = re.compile(
    r"(ÐºÐ¾Ð³Ð´Ð°|Ð´Ð°Ñ‚Ð°|Ð²Ñ‹Ð¹Ð´ÐµÑ‚|Ñ€ÐµÐ»Ð¸Ð·|Ð½Ð¾Ð²Ð¾ÑÑ‚|ÐºÑƒÑ€Ñ|Ñ†ÐµÐ½Ð°|Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·|Ñ‡Ñ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ðµ|ÐºÑ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ð¹|Ð½Ð°Ð¹Ð´Ð¸|ÑÑÑ‹Ð»ÐºÐ°|Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»|Ð°Ð´Ñ€ÐµÑ|Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½|"
    r"Ð¿Ð¾Ð³Ð¾Ð´Ð°|ÑÐµÐ³Ð¾Ð´Ð½Ñ|ÑÐµÐ¹Ñ‡Ð°Ñ|ÑˆÑ‚Ñ€Ð°Ñ„|Ð·Ð°ÐºÐ¾Ð½|Ñ‚Ñ€ÐµÐ½Ð´|ÐºÐ¾Ñ‚Ð¸Ñ€Ð¾Ð²Ðº|Ð¾Ð±Ð·Ð¾Ñ€|Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸|Ð·Ð°Ð¿ÑƒÑÐº|update|Ð½Ð¾Ð²Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ)",
    re.IGNORECASE
)
_CAPABILITY_RE = re.compile(
    r"(Ð¼Ð¾Ð¶(ÐµÑˆÑŒ|Ð½Ð¾).{0,10}(Ð°Ð½Ð°Ð»Ð¸Ð·(Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ)?|Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²(Ð°Ñ‚ÑŒ|Ð°Ð½Ð¸Ðµ)).{0,10}(Ñ„Ð¾Ñ‚Ð¾|ÐºÐ°Ñ€Ñ‚Ð¸Ð½Ðº|Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½|image|picture)|"
    r"Ð°Ð½Ð°Ð»Ð¸Ð·(Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ)?.{0,8}(Ñ„Ð¾Ñ‚Ð¾|ÐºÐ°Ñ€Ñ‚Ð¸Ð½Ðº|Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½)|"
    r"(Ð¼Ð¾Ð¶(ÐµÑˆÑŒ|Ð½Ð¾).{0,10})?(Ð°Ð½Ð°Ð»Ð¸Ð·|Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ).{0,6}Ñ.{0,6}Ð²Ð¸Ð´ÐµÐ¾)",
    re.IGNORECASE
)

def is_smalltalk(text: str) -> bool:
    return bool(_SMALLTALK_RE.search(text.strip()))

def should_browse(text: str) -> bool:
    t = text.strip()
    if is_smalltalk(t):
        return False
    return bool(_NEWSY_RE.search(t) or "?" in t or len(t) > 80)

def is_vision_capability_question(text: str) -> bool:
    return bool(_CAPABILITY_RE.search(text))

# ========== UTILS ==========
async def typing(ctx: ContextTypes.DEFAULT_TYPE, chat_id: int):
    try:
        await ctx.bot.send_chat_action(chat_id, action=ChatAction.TYPING)
    except Exception:
        pass

def sniff_image_mime(data: bytes) -> str:
    if data.startswith(b"\xff\xd8"):
        return "image/jpeg"
    if data.startswith(b"\x89PNG"):
        return "image/png"
    if data[:4] == b"RIFF" and b"WEBP" in data[:16]:
        return "image/webp"
    return "image/jpeg"

def format_sources(items):
    if not items:
        return ""
    lines = []
    for i, it in enumerate(items, 1):
        title = it.get("title") or it.get("url") or "Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº"
        url = it.get("url") or ""
        lines.append(f"[{i}] {title} â€” {url}")
    return "\n\nÐ¡ÑÑ‹Ð»ÐºÐ¸:\n" + "\n".join(lines)

def tavily_search(query: str, max_results: int = 5):
    if not tavily:
        return None, []
    try:
        res = tavily.search(
            query=query,
            search_depth="advanced",
            max_results=max_results,
            include_answer=True,
            include_raw_content=False,
        )
        answer = res.get("answer") or ""
        results = res.get("results") or []
        return answer, results
    except Exception as e:
        log.exception("Tavily error: %s", e)
        return None, []

# ========== OPENAI HELPERS ==========
async def ask_openai_text(user_text: str, web_ctx: str = "") -> str:
    if not oai:
        return "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸ (ÐºÐ»ÑŽÑ‡/Ð»Ð¸Ð¼Ð¸Ñ‚). ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ Ð¿Ð¾Ð·Ð¶Ðµ."

    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    if web_ctx:
        messages.append({"role": "system", "content": f"ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¸Ð· Ð²ÐµÐ±-Ð¿Ð¾Ð¸ÑÐºÐ°:\n{web_ctx}"})
    messages.append({"role": "user", "content": user_text})

    try:
        resp = oai.chat.completions.create(
            model=OPENAI_MODEL,
            messages=messages,
            temperature=0.6,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        log.exception("OpenAI chat error: %s", e)
        return "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸ (Ð»Ð¸Ð¼Ð¸Ñ‚/ÐºÐ»ÑŽÑ‡). ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ Ð¿Ð¾Ð·Ð¶Ðµ."

async def ask_openai_vision(user_text: str, img_b64: str, mime: str) -> str:
    if not oai:
        return "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ (ÐºÐ»ÑŽÑ‡/Ð»Ð¸Ð¼Ð¸Ñ‚). ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ Ð¿Ð¾Ð·Ð¶Ðµ."
    try:
        resp = oai.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": VISION_SYSTEM_PROMPT},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": user_text or "ÐžÐ¿Ð¸ÑˆÐ¸, Ñ‡Ñ‚Ð¾ Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸ Ð¸ ÐºÐ°ÐºÐ¾Ð¹ Ñ‚Ð°Ð¼ Ñ‚ÐµÐºÑÑ‚."},
                        {"type": "image_url",
                         "image_url": {"url": f"data:{mime};base64,{img_b64}"}}
                    ]
                }
            ],
            temperature=0.4,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        log.exception("Vision error: %s", e)
        return "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ (Ð»Ð¸Ð¼Ð¸Ñ‚/ÐºÐ»ÑŽÑ‡). ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ Ð¿Ð¾Ð·Ð¶Ðµ."

# ========== STT: Deepgram -> Whisper fallback ==========
async def transcribe_audio(buf: BytesIO, filename_hint: str = "audio.ogg") -> str:
    data = buf.getvalue()

    # Deepgram
    if DEEPGRAM_API_KEY:
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                params = {"model": "nova-2", "language": "ru", "smart_format": "true", "punctuate": "true"}
                headers = {
                    "Authorization": f"Token {DEEPGRAM_API_KEY}",
                    "Content-Type": "audio/ogg" if filename_hint.endswith(".ogg") else "application/octet-stream",
                }
                r = await client.post("https://api.deepgram.com/v1/listen", params=params, headers=headers, content=data)
                r.raise_for_status()
                dg = r.json()
                text = (
                    dg.get("results", {}).get("channels", [{}])[0].get("alternatives", [{}])[0].get("transcript", "")
                ).strip()
                if text:
                    return text
        except Exception as e:
            log.exception("Deepgram STT error: %s", e)

    # OpenAI Whisper fallback
    if oai:
        try:
            buf2 = BytesIO(data); buf2.seek(0)
            setattr(buf2, "name", filename_hint)
            tr = oai.audio.transcriptions.create(model=TRANSCRIBE_MODEL, file=buf2)
            return (tr.text or "").strip()
        except Exception as e:
            log.exception("Whisper STT error: %s", e)

    return ""

# ========== KEYBOARD (ReplyKeyboard + WebApp) ==========
def build_main_keyboard() -> ReplyKeyboardMarkup:
    # Ð•ÑÐ»Ð¸ WEBAPP_URL Ð½Ðµ Ð·Ð°Ð´Ð°Ð½ â€” Ð¾Ñ‚ÐºÑ€Ð¾ÐµÐ¼ ÑÐµÑ€Ð²ÐµÑ€ Ð±Ð¾Ñ‚Ð° (ÑÐºÐ¾Ñ€ÐµÐµ Ð²ÑÐµÐ³Ð¾ 404). ÐŸÐ¾ÑÑ‚Ð¾Ð¼Ñƒ Ð»ÑƒÑ‡ÑˆÐµ Ð·Ð°Ð´Ð°Ñ‚ÑŒ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ!
    base_url = WEBAPP_URL or PUBLIC_URL
    premium_url = f"{(WEBAPP_URL or PUBLIC_URL)}{WEBAPP_PREMIUM_PATH}"

    kb = ReplyKeyboardMarkup(
        [
            [KeyboardButton("ðŸ§­ ÐœÐµÐ½ÑŽ", web_app=WebAppInfo(url=base_url))],
            [KeyboardButton("âš™ï¸ Ð ÐµÐ¶Ð¸Ð¼Ñ‹"), KeyboardButton("ðŸ§© ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹")],
            [KeyboardButton("â­ ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ°", web_app=WebAppInfo(url=premium_url))],
        ],
        resize_keyboard=True
    )
    return kb

# ========== HANDLERS ==========
async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð¾Ð´Ð½Ð¾ Ð¿Ñ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ Ñ ÐºÐ½Ð¾Ð¿ÐºÐ°Ð¼Ð¸ (Ð±ÐµÐ· Ð²Ñ‚Ð¾Ñ€Ð¾Ð³Ð¾ Â«ÐŸÐ¾Ð´ÑÐºÐ°Ð·ÐºÐ¸Â»)
    if BANNER_URL:
        try:
            # ÐŸÐ¾ÐºÐ°Ð¶ÐµÐ¼ Ð±Ð°Ð½Ð½ÐµÑ€ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾ (Ð±ÐµÐ· Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ¸, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð´ÑƒÐ±Ð»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‚ÐµÐºÑÑ‚)
            await update.effective_message.reply_photo(BANNER_URL)
        except Exception:
            pass

    await update.effective_message.reply_text(
        START_TEXT,
        reply_markup=build_main_keyboard(),
        disable_web_page_preview=True,
        parse_mode="Markdown"
    )

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (update.message.text or "").strip()
    chat_id = update.effective_chat.id

    # ÐšÐ½Ð¾Ð¿ÐºÐ¸/ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ Â«Ð ÐµÐ¶Ð¸Ð¼Ñ‹Â» Ð¸ Â«ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹Â»
    if text in ("âš™ï¸ Ð ÐµÐ¶Ð¸Ð¼Ñ‹", "Ð ÐµÐ¶Ð¸Ð¼Ñ‹", "/modes"):
        await update.message.reply_text(MODES_TEXT, parse_mode="Markdown", disable_web_page_preview=True)
        return
    if text in ("ðŸ§© ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹", "ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹", "/examples"):
        await update.message.reply_text(EXAMPLES_TEXT, parse_mode="Markdown", disable_web_page_preview=True)
        return

    # Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ñ€Ð¾ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹/Ð²Ð¸Ð´ÐµÐ¾
    if is_vision_capability_question(text):
        await update.message.reply_text(VISION_CAPABILITY_HELP, disable_web_page_preview=True)
        return

    await typing(context, chat_id)

    # Small talk â€” Ð±ÐµÐ· Ð²ÐµÐ±Ð°
    if is_smalltalk(text):
        reply = await ask_openai_text(text)
        await update.message.reply_text(reply)
        return

    # Ð’ÐµÐ±-Ð¿Ð¾Ð¸ÑÐº?
    web_ctx = ""
    sources = []
    if should_browse(text):
        answer_from_search, results = tavily_search(text, max_results=5)
        sources = results or []
        ctx_lines = []
        if answer_from_search:
            ctx_lines.append(f"ÐšÑ€Ð°Ñ‚ÐºÐ°Ñ ÑÐ²Ð¾Ð´ÐºÐ° Ð¿Ð¾Ð¸ÑÐºÐ¾Ð¼: {answer_from_search}")
        for i, it in enumerate(sources, 1):
            ctx_lines.append(f"[{i}] {it.get('title','')}: {it.get('url','')}")
        web_ctx = "\n".join(ctx_lines)

    # ÐžÑ‚Ð²ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸
    answer = await ask_openai_text(text, web_ctx=web_ctx)
    answer += format_sources(sources)
    await update.message.reply_text(answer, disable_web_page_preview=False)

async def _handle_image_bytes(update: Update, context: ContextTypes.DEFAULT_TYPE, data: bytes, user_text: str):
    mime = sniff_image_mime(data)
    img_b64 = base64.b64encode(data).decode("ascii")
    answer = await ask_openai_vision(user_text, img_b64, mime)
    await update.message.reply_text(answer, disable_web_page_preview=True)

async def on_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await typing(context, chat_id)
    photo = update.message.photo[-1]
    file = await context.bot.get_file(photo.file_id)
    buf = BytesIO(); await file.download_to_memory(buf)
    user_text = (update.message.caption or "").strip()
    await _handle_image_bytes(update, context, buf.getvalue(), user_text)

async def on_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await typing(context, chat_id)

    doc = update.message.document
    mime = (doc.mime_type or "").lower()
    if mime.startswith("image/"):
        file = await context.bot.get_file(doc.file_id)
        buf = BytesIO(); await file.download_to_memory(buf)
        user_text = (update.message.caption or "").strip()
        await _handle_image_bytes(update, context, buf.getvalue(), user_text)
    else:
        await update.message.reply_text(
            "Ð¤Ð°Ð¹Ð» Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð». Ð•ÑÐ»Ð¸ ÑÑ‚Ð¾ PDF/Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ â€” Ð¿Ñ€Ð¸ÑˆÐ»Ð¸ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹ ÐºÐ°Ðº Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¸Ð»Ð¸ ÑƒÐºÐ°Ð¶Ð¸, Ñ‡Ñ‚Ð¾ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ."
        )

async def on_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await typing(context, chat_id)

    voice = update.message.voice
    file = await context.bot.get_file(voice.file_id)
    buf = BytesIO(); await file.download_to_memory(buf)

    text = await transcribe_audio(buf, filename_hint="audio.ogg")
    if not text:
        await update.message.reply_text("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ñ‚ÑŒ Ð³Ð¾Ð»Ð¾Ñ. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ ÐµÑ‰Ñ‘ Ñ€Ð°Ð·.")
        return

    prefix = f"ðŸ—£ï¸ Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð»: Â«{text}Â»\n\n"
    web_ctx = ""
    sources = []
    if should_browse(text):
        answer_from_search, results = tavily_search(text, max_results=5)
        sources = results or []
        ctx_lines = []
        if answer_from_search:
            ctx_lines.append(f"ÐšÑ€Ð°Ñ‚ÐºÐ°Ñ ÑÐ²Ð¾Ð´ÐºÐ° Ð¿Ð¾Ð¸ÑÐºÐ¾Ð¼: {answer_from_search}")
        for i, it in enumerate(sources, 1):
            ctx_lines.append(f"[{i}] {it.get('title','')}: {it.get('url','')}")
        web_ctx = "\n".join(ctx_lines)

    answer = await ask_openai_text(text, web_ctx=web_ctx)
    answer = prefix + answer + format_sources(sources)
    await update.message.reply_text(answer, disable_web_page_preview=False)

async def on_audio(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await typing(context, chat_id)

    audio = update.message.audio
    file = await context.bot.get_file(audio.file_id)
    buf = BytesIO(); await file.download_to_memory(buf)

    filename = (audio.file_name or "audio.mp3")
    text = await transcribe_audio(buf, filename_hint=filename)
    if not text:
        await update.message.reply_text("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ñ‚ÑŒ Ð°ÑƒÐ´Ð¸Ð¾. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ ÐµÑ‰Ñ‘ Ñ€Ð°Ð·.")
        return

    prefix = f"ðŸ—£ï¸ Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð»: Â«{text}Â»\n\n"
    web_ctx = ""
    sources = []
    if should_browse(text):
        answer_from_search, results = tavily_search(text, max_results=5)
        sources = results or []
        ctx_lines = []
        if answer_from_search:
            ctx_lines.append(f"ÐšÑ€Ð°Ñ‚ÐºÐ°Ñ ÑÐ²Ð¾Ð´ÐºÐ° Ð¿Ð¾Ð¸ÑÐºÐ¾Ð¼: {answer_from_search}")
        for i, it in enumerate(sources, 1):
            ctx_lines.append(f"[{i}] {it.get('title','')}: {it.get('url','')}")
        web_ctx = "\n".join(ctx_lines)

    answer = await ask_openai_text(text, web_ctx=web_ctx)
    answer = prefix + answer + format_sources(sources)
    await update.message.reply_text(answer, disable_web_page_preview=False)

async def on_video(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "Ð”Ð°, Ð¿Ð¾Ð¼Ð¾Ð³Ñƒ Ñ Ð²Ð¸Ð´ÐµÐ¾: Ð¿Ñ€Ð¸ÑˆÐ»Ð¸ 1â€“3 ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… ÐºÐ°Ð´Ñ€Ð° (ÑÐºÑ€Ð¸Ð½ÑˆÐ¾Ñ‚Ð°) â€” Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ Ð¿Ð¾ ÐºÐ°Ð´Ñ€Ð°Ð¼ Ð¸ Ð¾Ñ‚Ð²ÐµÑ‡Ñƒ Ð¿Ð¾ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸ÑŽ. ðŸ“½ï¸"
    )

# ========== BOOTSTRAP ==========
def build_app():
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("modes", lambda u,c: u.message.reply_text(MODES_TEXT, parse_mode="Markdown")))
    app.add_handler(CommandHandler("examples", lambda u,c: u.message.reply_text(EXAMPLES_TEXT, parse_mode="Markdown")))
    # Ñ‚ÐµÐºÑÑ‚
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))
    # Ñ„Ð¾Ñ‚Ð¾ Ð¸ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹-ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐ¸
    app.add_handler(MessageHandler(filters.PHOTO, on_photo))
    app.add_handler(MessageHandler(filters.Document.IMAGE, on_document))
    # Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ñ‹Ðµ Ð¸ Ð°ÑƒÐ´Ð¸Ð¾
    app.add_handler(MessageHandler(filters.VOICE, on_voice))
    app.add_handler(MessageHandler(filters.AUDIO, on_audio))
    # Ð²Ð¸Ð´ÐµÐ¾
    app.add_handler(MessageHandler(filters.VIDEO, on_video))
    return app

def run_webhook(app):
    url_path = f"webhook/{BOT_TOKEN}"
    webhook_url = f"{PUBLIC_URL.rstrip('/')}/{url_path}"
    log.info("Starting webhook on 0.0.0.0:%s  ->  %s", PORT, webhook_url)
    app.run_webhook(
        listen="0.0.0.0",
        port=PORT,
        url_path=url_path,
        webhook_url=webhook_url,
        secret_token=WEBHOOK_SECRET or None,
        drop_pending_updates=True,
    )

def main():
    app = build_app()
    run_webhook(app)

if __name__ == "__main__":
    main()

# -*- coding: utf-8 -*-
import os
import re
import base64
import logging
from io import BytesIO

import httpx
from telegram import Update, ReplyKeyboardMarkup, KeyboardButton, WebAppInfo
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
)
from telegram.constants import ChatAction

# ========== LOGGING ==========
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
)
log = logging.getLogger("gpt-bot")

# ========== ENV ==========
BOT_TOKEN        = os.environ.get("BOT_TOKEN", "").strip()
PUBLIC_URL       = os.environ.get("PUBLIC_URL", "").strip()       # https://<subdomain>.onrender.com (—Å–µ—Ä–≤–µ—Ä –±–æ—Ç–∞)
OPENAI_API_KEY   = os.environ.get("OPENAI_API_KEY", "").strip()
OPENAI_MODEL     = os.environ.get("OPENAI_MODEL", "gpt-4o-mini").strip()
WEBHOOK_SECRET   = os.environ.get("WEBHOOK_SECRET", "").strip()
BANNER_URL       = os.environ.get("BANNER_URL", "").strip()       # –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ (–∫–∞—Ä—Ç–∏–Ω–∫–∞ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è)
TAVILY_API_KEY   = os.environ.get("TAVILY_API_KEY", "").strip()
DEEPGRAM_API_KEY = os.environ.get("DEEPGRAM_API_KEY", "").strip()
TRANSCRIBE_MODEL = os.environ.get("OPENAI_TRANSCRIBE_MODEL", "whisper-1").strip()
WEBAPP_URL       = os.environ.get("WEBAPP_URL", "").strip().rstrip("/")  # –¥–æ–º–µ–Ω –º–∏–Ω–∏-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è! (–Ω–µ —Å–µ—Ä–≤–µ—Ä –±–æ—Ç–∞)
WEBAPP_PREMIUM_PATH = os.environ.get("WEBAPP_PREMIUM_PATH", "/premium").strip()  # –¥–ª—è SPA –º–æ–∂–Ω–æ –ø–æ—Å—Ç–∞–≤–∏—Ç—å "#/premium"
PORT             = int(os.environ.get("PORT", "10000"))

if not BOT_TOKEN:
    raise RuntimeError("ENV BOT_TOKEN is required")
if not PUBLIC_URL or not PUBLIC_URL.startswith("http"):
    raise RuntimeError("ENV PUBLIC_URL must look like https://xxx.onrender.com")

# ========== OPENAI / Tavily ==========
from openai import OpenAI
oai = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

try:
    if TAVILY_API_KEY:
        from tavily import TavilyClient
        tavily = TavilyClient(api_key=TAVILY_API_KEY)
    else:
        tavily = None
except Exception:
    tavily = None

# ========== PROMPTS ==========
SYSTEM_PROMPT = (
    "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º. "
    "–û—Ç–≤–µ—á–∞–π –ø–æ —Å—É—Ç–∏, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π —Å–ø–∏—Å–∫–∞–º–∏/—à–∞–≥–∞–º–∏, –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã. "
    "–ï—Å–ª–∏ —Å—Å—ã–ª–∞–µ—à—å—Å—è –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ ‚Äî –≤ –∫–æ–Ω—Ü–µ –¥–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫."
)

VISION_SYSTEM_PROMPT = (
    "–¢—ã —á—ë—Ç–∫–æ –æ–ø–∏—Å—ã–≤–∞–µ—à—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: –æ–±—ä–µ–∫—Ç—ã, —Ç–µ–∫—Å—Ç, —Å—Ö–µ–º—ã, –≥—Ä–∞—Ñ–∏–∫–∏. "
    "–ù–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–π –ª–∏—á–Ω–æ—Å—Ç–∏ –ª—é–¥–µ–π –∏ –Ω–µ –ø–∏—à–∏ –∏–º–µ–Ω–∞, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –Ω–∞–ø–µ—á–∞—Ç–∞–Ω—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."
)

VISION_CAPABILITY_HELP = (
    "–î–∞ ‚Äî –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –ø–æ–º–æ–≥–∞—é —Å –≤–∏–¥–µ–æ –ø–æ –∫–∞–¥—Ä–∞–º, –∞ –µ—â—ë —Ä–∞—Å–ø–æ–∑–Ω–∞—é –≥–æ–ª–æ—Å. ‚úÖ\n\n"
    "‚Ä¢ –§–æ—Ç–æ/—Å–∫—Ä–∏–Ω—à–æ—Ç—ã: JPG/PNG/WebP (–¥–æ ~10 –ú–ë) ‚Äî –æ–ø–∏—à—É, –ø—Ä–æ—á–∏—Ç–∞—é —Ç–µ–∫—Å—Ç, —Ä–∞–∑–±–µ—Ä—É –≥—Ä–∞—Ñ–∏–∫–∏.\n"
    "‚Ä¢ –î–æ–∫—É–º–µ–Ω—Ç—ã/PDF: –ø—Ä–∏—à–ª–∏ –∫–∞–∫ *—Ñ–∞–π–ª*, –∏–∑–≤–ª–µ–∫—É —Ç–µ–∫—Å—Ç/—Ç–∞–±–ª–∏—Ü—ã.\n"
    "‚Ä¢ –í–∏–¥–µ–æ: –ø—Ä–∏—à–ª–∏ 1‚Äì3 –∫–ª—é—á–µ–≤—ã—Ö –∫–∞–¥—Ä–∞ (—Å–∫—Ä–∏–Ω—à–æ—Ç–∞) ‚Äî –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø–æ –∫–∞–¥—Ä–∞–º.\n"
    "‚Ä¢ –ì–æ–ª–æ—Å–æ–≤—ã–µ/–∞—É–¥–∏–æ: —Ä–∞—Å–ø–æ–∑–Ω–∞—é —Ä–µ—á—å –∏ –æ—Ç–≤–µ—á—É –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é."
)

# –ö—Ä–∞—Å–∏–≤–æ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ (–æ–¥–Ω–æ, –±–µ–∑ ¬´–ø–æ–¥—Å–∫–∞–∑–æ–∫¬ª –Ω–∏–∂–µ)
START_TEXT = (
    "**GPT-5 PRO ‚Äî —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –Ω–∞ –±–∞–∑–µ ChatGPT ü§ñ**\n"
    "–û—Ç–≤–µ—á–∞—é –ø–æ –¥–µ–ª—É, *–∏—â—É —Ñ–∞–∫—Ç—ã –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ* üåê, *–ø–æ–Ω–∏–º–∞—é —Ñ–æ—Ç–æ* üñºÔ∏è –∏ *—Ä–∞—Å–ø–æ–∑–Ω–∞—é –≥–æ–ª–æ—Å* üéôÔ∏è.\n\n"
    "**–ß—Ç–æ —É–º–µ—é:**\n"
    "‚Ä¢ ‚úçÔ∏è –≠—Å—Å–µ/—Ä–µ—Ñ–µ—Ä–∞—Ç—ã/–æ—Ç—á—ë—Ç—ã, –ø–ª–∞–Ω—ã, –ø—Ä–∞–≤–∫–∏.\n"
    "‚Ä¢ üßÆ –†–∞—Å—á—ë—Ç—ã, —Ñ–æ—Ä–º—É–ª—ã, —Ç–∞–±–ª–∏—Ü—ã, –Ω–∞–±—Ä–æ—Å–∫–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤.\n"
    "‚Ä¢ üìö –û–±—ä—è—Å–Ω–µ–Ω–∏—è, –∫–æ–Ω—Å–ø–µ–∫—Ç—ã, –ø–µ—Ä–µ–≤–æ–¥—ã.\n"
    "‚Ä¢ üîé –ü–æ–∏—Å–∫ –≤ —Å–µ—Ç–∏ —Å–æ *—Å—Å—ã–ª–∫–∞–º–∏*.\n"
    "‚Ä¢ üñºÔ∏è –§–æ—Ç–æ: –æ–ø–∏—Å–∞–Ω–∏–µ, OCR, —Å—Ö–µ–º—ã/–≥—Ä–∞—Ñ–∏–∫–∏.\n"
    "‚Ä¢ üéß –ì–æ–ª–æ—Å/–∞—É–¥–∏–æ: —Ä–∞—Å–ø–æ–∑–Ω–∞—é –∏ –æ—Ç–≤–µ—á–∞—é –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é.\n"
    "‚Ä¢ üíº –†–∞–±–æ—Ç–∞: –ø–∏—Å—å–º–∞, –±—Ä–∏—Ñ—ã, —á–µ–∫-–ª–∏—Å—Ç—ã, –∏–¥–µ–∏.\n\n"
    "–ö–Ω–æ–ø–∫–∏: üß≠ –ú–µ–Ω—é ¬∑ ‚öôÔ∏è –†–µ–∂–∏–º—ã ¬∑ üß© –ü—Ä–∏–º–µ—Ä—ã ¬∑ ‚≠ê –ü–æ–¥–ø–∏—Å–∫–∞"
)

MODES_TEXT = (
    "‚öôÔ∏è **–†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã**\n"
    "‚Ä¢ üí¨ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π ‚Äî –æ–±—ã—á–Ω—ã–π –¥–∏–∞–ª–æ–≥.\n"
    "‚Ä¢ üß† –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å ‚Äî —Ñ–∞–∫—Ç—ã/–∏—Å—Ç–æ—á–Ω–∏–∫–∏, —Å–≤–æ–¥–∫–∏.\n"
    "‚Ä¢ ‚úçÔ∏è –†–µ–¥–∞–∫—Ç–æ—Ä ‚Äî –ø—Ä–∞–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞, —Å—Ç–∏–ª—å, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞.\n"
    "‚Ä¢ üìä –ê–Ω–∞–ª–∏—Ç–∏–∫ ‚Äî —Ñ–æ—Ä–º—É–ª—ã, —Ç–∞–±–ª–∏—Ü—ã, —Ä–∞—Å—á—ë—Ç–Ω—ã–µ —à–∞–≥–∏.\n"
    "‚Ä¢ üñºÔ∏è –í–∏–∑—É–∞–ª—å–Ω—ã–π ‚Äî –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, OCR, —Å—Ö–µ–º—ã.\n"
    "‚Ä¢ üéôÔ∏è –ì–æ–ª–æ—Å ‚Äî —Ä–∞—Å–ø–æ–∑–Ω–∞—é –∞—É–¥–∏–æ –∏ –æ—Ç–≤–µ—á–∞—é –ø–æ —Å—É—Ç–∏.\n\n"
    "–í—ã–±–∏—Ä–∞–π —Ä–µ–∂–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –∑–∞–¥–∞—á—É üòâ"
)

EXAMPLES_TEXT = (
    "üß© **–ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤**\n"
    "‚Ä¢ ¬´–°–¥–µ–ª–∞–π –∫–æ–Ω—Å–ø–µ–∫—Ç –≥–ª–∞–≤—ã 3 –∏ –≤—ã–¥–µ–ª–∏ —Ñ–æ—Ä–º—É–ª—ã¬ª\n"
    "‚Ä¢ ¬´–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π CSV, –Ω–∞–π–¥–∏ —Ç—Ä–µ–Ω–¥—ã –∏ —Å–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–∏–π –≤—ã–≤–æ–¥¬ª\n"
    "‚Ä¢ ¬´–°–æ—Å—Ç–∞–≤—å –ø–∏—Å—å–º–æ –∫–ª–∏–µ–Ω—Ç—É, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ –ø–æ –¥–µ–ª—É¬ª\n"
    "‚Ä¢ ¬´–°—É–º–º–∏—Ä—É–π —Å—Ç–∞—Ç—å—é –∏–∑ —Å—Å—ã–ª–∫–∏ –∏ –¥–∞–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏¬ª\n"
    "‚Ä¢ ¬´–û–ø–∏—à–∏ —Ç–µ–∫—Å—Ç –Ω–∞ —Ñ–æ—Ç–æ –∏ –∏–∑–≤–ª–µ–∫–∏ —Ç–∞–±–ª–∏—Ü—É¬ª"
)

# ========== HEURISTICS ==========
_SMALLTALK_RE = re.compile(
    r"^(–ø—Ä–∏–≤–µ—Ç|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π|–¥–æ–±—Ä—ã–π\s*(–¥–µ–Ω—å|–≤–µ—á–µ—Ä|—É—Ç—Ä–æ)|—Ö–∏|hi|hello|—Ö–µ–ª–ª–æ|–∫–∞–∫ –¥–µ–ª–∞|—Å–ø–∞—Å–∏–±–æ|–ø–æ–∫–∞)\b",
    re.IGNORECASE
)
_NEWSY_RE = re.compile(
    r"(–∫–æ–≥–¥–∞|–¥–∞—Ç–∞|–≤—ã–π–¥–µ—Ç|—Ä–µ–ª–∏–∑|–Ω–æ–≤–æ—Å—Ç|–∫—É—Ä—Å|—Ü–µ–Ω–∞|–ø—Ä–æ–≥–Ω–æ–∑|—á—Ç–æ —Ç–∞–∫–æ–µ|–∫—Ç–æ —Ç–∞–∫–æ–π|–Ω–∞–π–¥–∏|—Å—Å—ã–ª–∫–∞|–æ—Ñ–∏—Ü–∏–∞–ª|–∞–¥—Ä–µ—Å|—Ç–µ–ª–µ—Ñ–æ–Ω|"
    r"–ø–æ–≥–æ–¥–∞|—Å–µ–≥–æ–¥–Ω—è|—Å–µ–π—á–∞—Å|—à—Ç—Ä–∞—Ñ|–∑–∞–∫–æ–Ω|—Ç—Ä–µ–Ω–¥|–∫–æ—Ç–∏—Ä–æ–≤–∫|–æ–±–∑–æ—Ä|—Ä–∞—Å–ø–∏—Å–∞–Ω–∏|–∑–∞–ø—É—Å–∫|update|–Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è)",
    re.IGNORECASE
)
_CAPABILITY_RE = re.compile(
    r"(–º–æ–∂(–µ—à—å|–Ω–æ).{0,10}(–∞–Ω–∞–ª–∏–∑(–∏—Ä–æ–≤–∞—Ç—å)?|—Ä–∞—Å–ø–æ–∑–Ω–∞–≤(–∞—Ç—å|–∞–Ω–∏–µ)).{0,10}(—Ñ–æ—Ç–æ|–∫–∞—Ä—Ç–∏–Ω–∫|–∏–∑–æ–±—Ä–∞–∂–µ–Ω|image|picture)|"
    r"–∞–Ω–∞–ª–∏–∑(–∏—Ä–æ–≤–∞—Ç—å)?.{0,8}(—Ñ–æ—Ç–æ|–∫–∞—Ä—Ç–∏–Ω–∫|–∏–∑–æ–±—Ä–∞–∂–µ–Ω)|"
    r"(–º–æ–∂(–µ—à—å|–Ω–æ).{0,10})?(–∞–Ω–∞–ª–∏–∑|—Ä–∞–±–æ—Ç–∞—Ç—å).{0,6}—Å.{0,6}–≤–∏–¥–µ–æ)",
    re.IGNORECASE
)

def is_smalltalk(text: str) -> bool:
    return bool(_SMALLTALK_RE.search(text.strip()))

def should_browse(text: str) -> bool:
    t = text.strip()
    if is_smalltalk(t):
        return False
    return bool(_NEWSY_RE.search(t) or "?" in t or len(t) > 80)

def is_vision_capability_question(text: str) -> bool:
    return bool(_CAPABILITY_RE.search(text))

# ========== UTILS ==========
async def typing(ctx: ContextTypes.DEFAULT_TYPE, chat_id: int):
    try:
        await ctx.bot.send_chat_action(chat_id, action=ChatAction.TYPING)
    except Exception:
        pass

def sniff_image_mime(data: bytes) -> str:
    if data.startswith(b"\xff\xd8"):
        return "image/jpeg"
    if data.startswith(b"\x89PNG"):
        return "image/png"
    if data[:4] == b"RIFF" and b"WEBP" in data[:16]:
        return "image/webp"
    return "image/jpeg"

def format_sources(items):
    if not items:
        return ""
    lines = []
    for i, it in enumerate(items, 1):
        title = it.get("title") or it.get("url") or "–ò—Å—Ç–æ—á–Ω–∏–∫"
        url = it.get("url") or ""
        lines.append(f"[{i}] {title} ‚Äî {url}")
    return "\n\n–°—Å—ã–ª–∫–∏:\n" + "\n".join(lines)

def tavily_search(query: str, max_results: int = 5):
    if not tavily:
        return None, []
    try:
        res = tavily.search(
            query=query,
            search_depth="advanced",
            max_results=max_results,
            include_answer=True,
            include_raw_content=False,
        )
        answer = res.get("answer") or ""
        results = res.get("results") or []
        return answer, results
    except Exception as e:
        log.exception("Tavily error: %s", e)
        return None, []

# ========== OPENAI HELPERS ==========
async def ask_openai_text(user_text: str, web_ctx: str = "") -> str:
    if not oai:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ (–∫–ª—é—á/–ª–∏–º–∏—Ç). –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ."

    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    if web_ctx:
        messages.append({"role": "system", "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –≤–µ–±-–ø–æ–∏—Å–∫–∞:\n{web_ctx}"})
    messages.append({"role": "user", "content": user_text})

    try:
        resp = oai.chat.completions.create(
            model=OPENAI_MODEL,
            messages=messages,
            temperature=0.6,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        log.exception("OpenAI chat error: %s", e)
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ (–ª–∏–º–∏—Ç/–∫–ª—é—á). –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ."

async def ask_openai_vision(user_text: str, img_b64: str, mime: str) -> str:
    if not oai:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–∫–ª—é—á/–ª–∏–º–∏—Ç). –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ."
    try:
        resp = oai.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": VISION_SYSTEM_PROMPT},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": user_text or "–û–ø–∏—à–∏, —á—Ç–æ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∏ –∫–∞–∫–æ–π —Ç–∞–º —Ç–µ–∫—Å—Ç."},
                        {"type": "image_url",
                         "image_url": {"url": f"data:{mime};base64,{img_b64}"}}
                    ]
                }
            ],
            temperature=0.4,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        log.exception("Vision error: %s", e)
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–ª–∏–º–∏—Ç/–∫–ª—é—á). –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ."

# ========== STT: Deepgram -> Whisper fallback ==========
async def transcribe_audio(buf: BytesIO, filename_hint: str = "audio.ogg") -> str:
    data = buf.getvalue()

    # Deepgram
    if DEEPGRAM_API_KEY:
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                params = {"model": "nova-2", "language": "ru", "smart_format": "true", "punctuate": "true"}
                headers = {
                    "Authorization": f"Token {DEEPGRAM_API_KEY}",
                    "Content-Type": "audio/ogg" if filename_hint.endswith(".ogg") else "application/octet-stream",
                }
                r = await client.post("https://api.deepgram.com/v1/listen", params=params, headers=headers, content=data)
                r.raise_for_status()
                dg = r.json()
                text = (
                    dg.get("results", {}).get("channels", [{}])[0].get("alternatives", [{}])[0].get("transcript", "")
                ).strip()
                if text:
                    return text
        except Exception as e:
            log.exception("Deepgram STT error: %s", e)

    # OpenAI Whisper fallback
    if oai:
        try:
            buf2 = BytesIO(data); buf2.seek(0)
            setattr(buf2, "name", filename_hint)
            tr = oai.audio.transcriptions.create(model=TRANSCRIBE_MODEL, file=buf2)
            return (tr.text or "").strip()
        except Exception as e:
            log.exception("Whisper STT error: %s", e)

    return ""

# ========== KEYBOARD (ReplyKeyboard + WebApp) ==========
def build_main_keyboard() -> ReplyKeyboardMarkup:
    # –ï—Å–ª–∏ WEBAPP_URL –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –æ—Ç–∫—Ä–æ–µ–º —Å–µ—Ä–≤–µ—Ä –±–æ—Ç–∞ (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ 404). –ü–æ—ç—Ç–æ–º—É –ª—É—á—à–µ –∑–∞–¥–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é!
    base_url = WEBAPP_URL or PUBLIC_URL
    premium_url = f"{(WEBAPP_URL or PUBLIC_URL)}{WEBAPP_PREMIUM_PATH}"

    kb = ReplyKeyboardMarkup(
        [
            [KeyboardButton("üß≠ –ú–µ–Ω—é", web_app=WebAppInfo(url=base_url))],
            [KeyboardButton("‚öôÔ∏è –†–µ–∂–∏–º—ã"), KeyboardButton("üß© –ü—Ä–∏–º–µ—Ä—ã")],
            [KeyboardButton("‚≠ê –ü–æ–¥–ø–∏—Å–∫–∞", web_app=WebAppInfo(url=premium_url))],
        ],
        resize_keyboard=True
    )
    return kb

# ========== HANDLERS ==========
async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # –¢–æ–ª—å–∫–æ –æ–¥–Ω–æ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ —Å –∫–Ω–æ–ø–∫–∞–º–∏ (–±–µ–∑ –≤—Ç–æ—Ä–æ–≥–æ ¬´–ü–æ–¥—Å–∫–∞–∑–∫–∏¬ª)
    if BANNER_URL:
        try:
            # –ü–æ–∫–∞–∂–µ–º –±–∞–Ω–Ω–µ—Ä –æ—Ç–¥–µ–ª—å–Ω–æ (–±–µ–∑ –ø–æ–¥–ø–∏—Å–∏, —á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç)
            await update.effective_message.reply_photo(BANNER_URL)
        except Exception:
            pass

    await update.effective_message.reply_text(
        START_TEXT,
        reply_markup=build_main_keyboard(),
        disable_web_page_preview=True,
        parse_mode="Markdown"
    )

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (update.message.text or "").strip()
    chat_id = update.effective_chat.id

    # –ö–Ω–æ–ø–∫–∏/–∫–æ–º–∞–Ω–¥—ã ¬´–†–µ–∂–∏–º—ã¬ª –∏ ¬´–ü—Ä–∏–º–µ—Ä—ã¬ª
    if text in ("‚öôÔ∏è –†–µ–∂–∏–º—ã", "–†–µ–∂–∏–º—ã", "/modes"):
        await update.message.reply_text(MODES_TEXT, parse_mode="Markdown", disable_web_page_preview=True)
        return
    if text in ("üß© –ü—Ä–∏–º–µ—Ä—ã", "–ü—Ä–∏–º–µ—Ä—ã", "/examples"):
        await update.message.reply_text(EXAMPLES_TEXT, parse_mode="Markdown", disable_web_page_preview=True)
        return

    # –í–æ–ø—Ä–æ—Å –ø—Ä–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π/–≤–∏–¥–µ–æ
    if is_vision_capability_question(text):
        await update.message.reply_text(VISION_CAPABILITY_HELP, disable_web_page_preview=True)
        return

    await typing(context, chat_id)

    # Small talk ‚Äî –±–µ–∑ –≤–µ–±–∞
    if is_smalltalk(text):
        reply = await ask_openai_text(text)
        await update.message.reply_text(reply)
        return

    # –í–µ–±-–ø–æ–∏—Å–∫?
    web_ctx = ""
    sources = []
    if should_browse(text):
        answer_from_search, results = tavily_search(text, max_results=5)
        sources = results or []
        ctx_lines = []
        if answer_from_search:
            ctx_lines.append(f"–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ–∏—Å–∫–æ–º: {answer_from_search}")
        for i, it in enumerate(sources, 1):
            ctx_lines.append(f"[{i}] {it.get('title','')}: {it.get('url','')}")
        web_ctx = "\n".join(ctx_lines)

    # –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
    answer = await ask_openai_text(text, web_ctx=web_ctx)
    answer += format_sources(sources)
    await update.message.reply_text(answer, disable_web_page_preview=False)

async def _handle_image_bytes(update: Update, context: ContextTypes.DEFAULT_TYPE, data: bytes, user_text: str):
    mime = sniff_image_mime(data)
    img_b64 = base64.b64encode(data).decode("ascii")
    answer = await ask_openai_vision(user_text, img_b64, mime)
    await update.message.reply_text(answer, disable_web_page_preview=True)

async def on_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await typing(context, chat_id)
    photo = update.message.photo[-1]
    file = await context.bot.get_file(photo.file_id)
    buf = BytesIO(); await file.download_to_memory(buf)
    user_text = (update.message.caption or "").strip()
    await _handle_image_bytes(update, context, buf.getvalue(), user_text)

async def on_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await typing(context, chat_id)

    doc = update.message.document
    mime = (doc.mime_type or "").lower()
    if mime.startswith("image/"):
        file = await context.bot.get_file(doc.file_id)
        buf = BytesIO(); await file.download_to_memory(buf)
        user_text = (update.message.caption or "").strip()
        await _handle_image_bytes(update, context, buf.getvalue(), user_text)
    else:
        await update.message.reply_text(
            "–§–∞–π–ª –ø–æ–ª—É—á–∏–ª. –ï—Å–ª–∏ —ç—Ç–æ PDF/–¥–æ–∫—É–º–µ–Ω—Ç ‚Äî –ø—Ä–∏—à–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ —É–∫–∞–∂–∏, —á—Ç–æ –∏–∑–≤–ª–µ—á—å."
        )

async def on_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await typing(context, chat_id)

    voice = update.message.voice
    file = await context.bot.get_file(voice.file_id)
    buf = BytesIO(); await file.download_to_memory(buf)

    text = await transcribe_audio(buf, filename_hint="audio.ogg")
    if not text:
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.")
        return

    prefix = f"üó£Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–ª: ¬´{text}¬ª\n\n"
    web_ctx = ""
    sources = []
    if should_browse(text):
        answer_from_search, results = tavily_search(text, max_results=5)
        sources = results or []
        ctx_lines = []
        if answer_from_search:
            ctx_lines.append(f"–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ–∏—Å–∫–æ–º: {answer_from_search}")
        for i, it in enumerate(sources, 1):
            ctx_lines.append(f"[{i}] {it.get('title','')}: {it.get('url','')}")
        web_ctx = "\n".join(ctx_lines)

    answer = await ask_openai_text(text, web_ctx=web_ctx)
    answer = prefix + answer + format_sources(sources)
    await update.message.reply_text(answer, disable_web_page_preview=False)

async def on_audio(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await typing(context, chat_id)

    audio = update.message.audio
    file = await context.bot.get_file(audio.file_id)
    buf = BytesIO(); await file.download_to_memory(buf)

    filename = (audio.file_name or "audio.mp3")
    text = await transcribe_audio(buf, filename_hint=filename)
    if not text:
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∞—É–¥–∏–æ. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.")
        return

    prefix = f"üó£Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–ª: ¬´{text}¬ª\n\n"
    web_ctx = ""
    sources = []
    if should_browse(text):
        answer_from_search, results = tavily_search(text, max_results=5)
        sources = results or []
        ctx_lines = []
        if answer_from_search:
            ctx_lines.append(f"–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ–∏—Å–∫–æ–º: {answer_from_search}")
        for i, it in enumerate(sources, 1):
            ctx_lines.append(f"[{i}] {it.get('title','')}: {it.get('url','')}")
        web_ctx = "\n".join(ctx_lines)

    answer = await ask_openai_text(text, web_ctx=web_ctx)
    answer = prefix + answer + format_sources(sources)
    await update.message.reply_text(answer, disable_web_page_preview=False)

async def on_video(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–î–∞, –ø–æ–º–æ–≥—É —Å –≤–∏–¥–µ–æ: –ø—Ä–∏—à–ª–∏ 1‚Äì3 –∫–ª—é—á–µ–≤—ã—Ö –∫–∞–¥—Ä–∞ (—Å–∫—Ä–∏–Ω—à–æ—Ç–∞) ‚Äî –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø–æ –∫–∞–¥—Ä–∞–º –∏ –æ—Ç–≤–µ—á—É –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é. üìΩÔ∏è"
    )

# ========== BOOTSTRAP ==========
def build_app():
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("modes", lambda u,c: u.message.reply_text(MODES_TEXT, parse_mode="Markdown")))
    app.add_handler(CommandHandler("examples", lambda u,c: u.message.reply_text(EXAMPLES_TEXT, parse_mode="Markdown")))
    # —Ç–µ–∫—Å—Ç
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))
    # —Ñ–æ—Ç–æ –∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã-–∫–∞—Ä—Ç–∏–Ω–∫–∏
    app.add_handler(MessageHandler(filters.PHOTO, on_photo))
    app.add_handler(MessageHandler(filters.Document.IMAGE, on_document))
    # –≥–æ–ª–æ—Å–æ–≤—ã–µ –∏ –∞—É–¥–∏–æ
    app.add_handler(MessageHandler(filters.VOICE, on_voice))
    app.add_handler(MessageHandler(filters.AUDIO, on_audio))
    # –≤–∏–¥–µ–æ
    app.add_handler(MessageHandler(filters.VIDEO, on_video))
    return app

def run_webhook(app):
    url_path = f"webhook/{BOT_TOKEN}"
    webhook_url = f"{PUBLIC_URL.rstrip('/')}/{url_path}"
    log.info("Starting webhook on 0.0.0.0:%s  ->  %s", PORT, webhook_url)
    app.run_webhook(
        listen="0.0.0.0",
        port=PORT,
        url_path=url_path,
        webhook_url=webhook_url,
        secret_token=WEBHOOK_SECRET or None,
        drop_pending_updates=True,
    )

def main():
    app = build_app()
    run_webhook(app)

if __name__ == "__main__":
    main()
